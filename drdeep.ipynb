{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:29:35.098802Z",
     "start_time": "2021-10-05T16:29:35.080955Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import torch.distributions.bernoulli as bernoulli\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import torch.distributions.bernoulli as bernoulli\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Source Data & Model (Concare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:29:36.117295Z",
     "start_time": "2021-10-05T16:29:36.111431Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = './data/Challenge/normalized_old/'\n",
    "small_part = False\n",
    "arg_timestep = 1.0\n",
    "batch_size = 256\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:29:36.891021Z",
     "start_time": "2021-10-05T16:29:36.886734Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_x = pickle.load(open(data_path + 'x.dat', 'rb'))\n",
    "# all_y = pickle.load(open(data_path + 'y.dat', 'rb'))\n",
    "# all_names = pickle.load(open(data_path + 'name.dat', 'rb'))\n",
    "# # time = pickle.load(open(data_path + 'time', 'rb'))\n",
    "# # weight = pickle.load(open(data_path + 'weight', 'rb'))\n",
    "# static = pickle.load(open(data_path + 'demo.dat', 'rb'))\n",
    "# mask_x = pickle.load(open(data_path + 'mask_x.dat', 'rb'))\n",
    "# mask_demo = pickle.load(open(data_path + 'mask_demo.dat', 'rb'))\n",
    "# all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "# print(all_x[0])\n",
    "# print(mask_x[0])\n",
    "# print(all_names[0])\n",
    "# print(static[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:29:59.998128Z",
     "start_time": "2021-10-05T16:29:37.148932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32268\n",
      "4033\n",
      "4035\n",
      "0.07267261683401513\n",
      "0.07265063228365981\n",
      "0.07286245353159851\n"
     ]
    }
   ],
   "source": [
    "train_x = pickle.load(open(data_path + 'train_x.dat', 'rb'))\n",
    "train_y = pickle.load(open(data_path + 'train_y.dat', 'rb'))\n",
    "train_names = pickle.load(open(data_path + 'train_names.dat', 'rb'))\n",
    "train_static = pickle.load(open(data_path + 'train_static.dat', 'rb'))\n",
    "train_x_len = pickle.load(open(data_path + 'train_x_len.dat', 'rb'))\n",
    "train_mask_x = pickle.load(open(data_path + 'train_mask_x.dat', 'rb'))\n",
    "\n",
    "dev_x = pickle.load(open(data_path + 'dev_x.dat', 'rb'))\n",
    "dev_y = pickle.load(open(data_path + 'dev_y.dat', 'rb'))\n",
    "dev_names = pickle.load(open(data_path + 'dev_names.dat', 'rb'))\n",
    "dev_static = pickle.load(open(data_path + 'dev_static.dat', 'rb'))\n",
    "dev_x_len = pickle.load(open(data_path + 'dev_x_len.dat', 'rb'))\n",
    "dev_mask_x = pickle.load(open(data_path + 'dev_mask_x.dat', 'rb'))\n",
    "\n",
    "test_x = pickle.load(open(data_path + 'test_x.dat', 'rb'))\n",
    "test_y = pickle.load(open(data_path + 'test_y.dat', 'rb'))\n",
    "test_names = pickle.load(open(data_path + 'test_names.dat', 'rb'))\n",
    "test_static = pickle.load(open(data_path + 'test_static.dat', 'rb'))\n",
    "test_x_len = pickle.load(open(data_path + 'test_x_len.dat', 'rb'))\n",
    "test_mask_x = pickle.load(open(data_path + 'test_mask_x.dat', 'rb'))\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(dev_x))\n",
    "print(len(test_x))\n",
    "print(sum(train_y)/len(train_y))\n",
    "print(sum(dev_y)/len(dev_y))\n",
    "print(sum(test_y)/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:35.467141Z",
     "start_time": "2021-10-04T14:25:35.457908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "# device = torch.device('cuda')\n",
    "print(\"available device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:35.560378Z",
     "start_time": "2021-10-04T14:25:35.469566Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:35.634245Z",
     "start_time": "2021-10-04T14:25:35.564473Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_re_loss(y_pred, y_true):\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:35.709393Z",
     "start_time": "2021-10-04T14:25:35.637560Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "\n",
    "    sents_padded = []\n",
    "\n",
    "    max_length = max([len(_) for _ in sents])\n",
    "    for i in sents:\n",
    "        padded = list(i) + [pad_token]*(max_length-len(i))\n",
    "        sents_padded.append(np.array(padded))\n",
    "\n",
    "\n",
    "    return np.array(sents_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:35.804116Z",
     "start_time": "2021-10-04T14:25:35.712739Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_iter(x, y, mask, lens, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx], mask[idx], lens[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_mask_x = [e[2] for e in examples]\n",
    "#         batch_name = [e[2] for e in examples]\n",
    "        batch_lens = [e[3] for e in examples]\n",
    "\n",
    "        yield batch_x, batch_y, batch_mask_x, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:35.911867Z",
     "start_time": "2021-10-04T14:25:35.807399Z"
    }
   },
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None):\n",
    "    \"\"\"length: B.\n",
    "    return B x max_len.\n",
    "    If max_len is None, then max of length will be used.\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1, 'Length shape should be 1 dimensional.'\n",
    "    max_len = max_len or length.max().item()\n",
    "    mask = torch.arange(max_len, device=length.device,\n",
    "                        dtype=length.dtype).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "    if dtype is not None:\n",
    "        mask = torch.as_tensor(mask, dtype=dtype, device=length.device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:36.065966Z",
     "start_time": "2021-10-04T14:25:35.917061Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', demographic_dim=12, time_aware=False, use_demographic=False):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "        self.use_demographic = use_demographic\n",
    "        self.demographic_dim = demographic_dim\n",
    "        self.time_aware = time_aware\n",
    "\n",
    "        # batch_time = torch.arange(0, batch_mask.size()[1], dtype=torch.float32).reshape(1, batch_mask.size()[1], 1)\n",
    "        # batch_time = batch_time.repeat(batch_mask.size()[0], 1, 1)\n",
    "        \n",
    "        if attention_type == 'add':\n",
    "            if self.time_aware == True:\n",
    "                # self.Wx = nn.Parameter(torch.randn(attention_input_dim+1, attention_hidden_dim))\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "                self.Wtime_aware = nn.Parameter(torch.randn(1, attention_hidden_dim))\n",
    "                nn.init.kaiming_uniform_(self.Wtime_aware, a=math.sqrt(5))\n",
    "            else:\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wd = nn.Parameter(torch.randn(demographic_dim, attention_hidden_dim))\n",
    "            self.bh = nn.Parameter(torch.zeros(attention_hidden_dim,))\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wd, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'mul':\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_input_dim, attention_input_dim))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'concat':\n",
    "            if self.time_aware == True:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim+1, attention_hidden_dim))\n",
    "            else:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        else:\n",
    "            raise RuntimeError('Wrong attention type.')\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, input, demo=None):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * time_step * hidden_dim(i)\n",
    "        #assert(input_dim == self.input_dim)\n",
    "\n",
    "        # time_decays = torch.zeros((time_step,time_step)).to(device)# t*t\n",
    "        # for this_time in range(time_step):\n",
    "        #     for pre_time in range(time_step):\n",
    "        #         if pre_time > this_time:\n",
    "        #             break\n",
    "        #         time_decays[this_time][pre_time] = torch.tensor(this_time - pre_time, dtype=torch.float32).to(device)\n",
    "        # b_time_decays = tile(time_decays, 0, batch_size).view(batch_size,time_step,time_step).unsqueeze(-1).to(device)# b t t 1\n",
    "\n",
    "        time_decays = torch.tensor(range(time_step-1,-1,-1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)# 1*t*1\n",
    "        b_time_decays = time_decays.repeat(batch_size,1,1)# b t 1\n",
    "        \n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
    "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            if self.time_aware == True:\n",
    "                # k_input = torch.cat((input, time), dim=-1)\n",
    "                k = torch.matmul(input, self.Wx)#b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "                time_hidden = torch.matmul(b_time_decays, self.Wtime_aware)#  b t h\n",
    "            else:\n",
    "                k = torch.matmul(input, self.Wx)# b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "            if self.use_demographic == True:\n",
    "                d = torch.matmul(demo, self.Wd) #B*H\n",
    "                d = torch.reshape(d, (batch_size, 1, self.attention_hidden_dim)) # b 1 h\n",
    "            h = q + k + self.bh # b t h\n",
    "            if self.time_aware == True:\n",
    "                h += time_hidden\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "        elif self.attention_type == 'mul':\n",
    "            e = torch.matmul(input[:,-1,:], self.Wa)#b i\n",
    "            e = torch.matmul(e.unsqueeze(1), input.permute(0,2,1)).squeeze() + self.ba #b t\n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input[:,-1,:].unsqueeze(1).repeat(1,time_step,1)# b t i\n",
    "            k = input\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            if self.time_aware == True:\n",
    "                c = torch.cat((c, b_time_decays), dim=-1) #B*T*2I+1\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        # e = torch.exp(e - torch.max(e, dim=-1, keepdim=True).values)\n",
    "        \n",
    "        # if self.attention_width is not None:\n",
    "        #     if self.history_only:\n",
    "        #         lower = torch.arange(0, time_step).to(device) - (self.attention_width - 1)\n",
    "        #     else:\n",
    "        #         lower = torch.arange(0, time_step).to(device) - self.attention_width // 2\n",
    "        #     lower = lower.unsqueeze(-1)\n",
    "        #     upper = lower + self.attention_width\n",
    "        #     indices = torch.arange(0, time_step).unsqueeze(0).to(device)\n",
    "        #     e = e * (lower <= indices).float() * (indices < upper).float()\n",
    "        \n",
    "        # s = torch.sum(e, dim=-1, keepdim=True)\n",
    "        # mask = subsequent_mask(time_step).to(device) # 1 t t 下三角\n",
    "        # scores = e.masked_fill(mask == 0, -1e9)# b t t 下三角\n",
    "        a = self.softmax(e) #B*T\n",
    "        v = torch.matmul(a.unsqueeze(1), input).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "class FinalAttentionQKV(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', dropout=None):\n",
    "        super(FinalAttentionQKV, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "\n",
    "\n",
    "        self.W_q = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_k = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_v = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "\n",
    "        self.W_out = nn.Linear(attention_hidden_dim, 1)\n",
    "\n",
    "        self.b_in = nn.Parameter(torch.zeros(1,))\n",
    "        self.b_out = nn.Parameter(torch.zeros(1,))\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.W_q.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_k.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_v.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_out.weight, a=math.sqrt(5))\n",
    "\n",
    "        self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "        self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "        self.ba = nn.Parameter(torch.zeros(1,))\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * input_dim + 1 * hidden_dim(i)\n",
    "        input_q = self.W_q(torch.mean(input,1)) # b h\n",
    "        input_k = self.W_k(input)# b t h\n",
    "        input_v = self.W_v(input)# b t h\n",
    "\n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "\n",
    "            q = torch.reshape(input_q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            h = q + input_k + self.b_in # b t h\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = self.W_out(h) # b t 1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "\n",
    "        elif self.attention_type == 'mul':\n",
    "            q = torch.reshape(input_q, (batch_size, self.attention_hidden_dim, 1)) #B*h 1\n",
    "            e = torch.matmul(input_k, q).squeeze()#b t\n",
    "            \n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input_q.unsqueeze(1).repeat(1,time_step,1)# b t h\n",
    "            k = input_k\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        a = self.softmax(e) #B*T\n",
    "        if self.dropout is not None:\n",
    "            a = self.dropout(a)\n",
    "        v = torch.matmul(a.unsqueeze(1), input_v).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)])).to(device)\n",
    "    return torch.index_select(a, dim, order_index).to(device)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module): # new added\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x)))), None\n",
    "\n",
    "# class PositionwiseFeedForwardConv(nn.Module):\n",
    "\n",
    "#     def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0):\n",
    "#         super(PositionalWiseFeedForward, self).__init__()\n",
    "#         self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
    "#         self.w2 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.layer_norm = nn.LayerNorm(model_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output = x.transpose(1, 2)\n",
    "#         output = self.w2(F.relu(self.w1(output)))\n",
    "#         output = self.dropout(output.transpose(1, 2))\n",
    "\n",
    "#         # add residual and norm layer\n",
    "#         output = self.layer_norm(x + output)\n",
    "#         return output\n",
    "\n",
    "class PositionalEncoding(nn.Module): # new added / not use anymore\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=400):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0 # 下三角矩阵\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)# b h t d_k\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k) # b h t t\n",
    "    if mask is not None:# 1 1 t t\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)# b h t t 下三角\n",
    "    p_attn = F.softmax(scores, dim = -1)# b h t t\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn # b h t v (d_k) \n",
    "    \n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, self.d_k * self.h), 3)\n",
    "        self.final_linear = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "        self.mask = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1) # 1 1 t t\n",
    "\n",
    "        nbatches = query.size(0)# b\n",
    "        input_dim = query.size(1)# i+1\n",
    "        feature_dim = query.size(-1)# i+1\n",
    "\n",
    "        #input size -> # batch_size * d_input * hidden_dim\n",
    "        \n",
    "        # d_model => h * d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))] # b num_head d_input d_k\n",
    "        \n",
    "        \n",
    "        querys = []\n",
    "        keys = []\n",
    "        values = []\n",
    "        for i in range(self.h):\n",
    "            querys.append(query[:,i].unsqueeze(1))\n",
    "            keys.append(key[:,i].unsqueeze(1))\n",
    "            values.append(value[:,i].unsqueeze(1))\n",
    "            \n",
    "        \n",
    "       \n",
    "        if self.training == True:\n",
    "\n",
    "            x, attn = attention(querys[0], keys[0], values[0], mask=mask, \n",
    "                                     dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
    "\n",
    "\n",
    "            self.attn = attn\n",
    "    #         self.mask = mask\n",
    "            attn1 = torch.mean(attn[:,0],1)\n",
    "    #         print(attn1.shape) # 256, 153\n",
    "    #         attn1_p = attn1/torch.sum(attn1,1).unsqueeze(1)\n",
    "\n",
    "            attn1_p = 0.1*self.sigmoid(lNorm(attn1)*10)\n",
    "    #         print(attn1_p.shape)\n",
    "\n",
    "\n",
    "            dis_b1 = bernoulli.Bernoulli(attn1_p)\n",
    "            to_mask1 = 1 - dis_b1.sample().to(device)\n",
    "            mask1 = to_mask1.unsqueeze(1).repeat(1,input_dim,1).unsqueeze(1)\n",
    "    #             print(attn1_p)\n",
    "    #             print(mask1)\n",
    "\n",
    "    #         mask1 = torch.ones((nbatches,input_dim,2*input_dim-1)).to(device)\n",
    "    #         mask1[0,0,attn1:attn1+1,:] = 0\n",
    "    #         mask1[0,0,:,attn1:attn1+1] = 0\n",
    "\n",
    "            tempx, attn = attention(querys[1], keys[1], values[1], mask=mask1, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            self.mask = mask1\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "            attn2 = attn1 + torch.mean(attn[:,0],1)\n",
    "    #         attn2_p = attn2/torch.sum(attn2,1).unsqueeze(1)\n",
    "            attn2_p = 0.1*self.sigmoid(lNorm(attn2)*10)\n",
    "\n",
    "            dis_b2 = bernoulli.Bernoulli(attn2_p)\n",
    "            to_mask2 = 1 - dis_b2.sample().to(device)\n",
    "            mask2 = to_mask2.unsqueeze(1).repeat(1,input_dim,1).unsqueeze(1)\n",
    "\n",
    "            tempx, attn = attention(querys[2], keys[2], values[2], mask=mask2, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            self.mask = torch.cat((self.mask, mask2), 1)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "    #         attn3 = torch.mean(attn[:,0],0)\n",
    "            attn3 = attn2 + torch.mean(attn[:,0],1)\n",
    "    #         attn3_p = attn3/torch.sum(attn3,1).unsqueeze(1)\n",
    "            attn3_p = 0.1*self.sigmoid(lNorm(attn3)*10)\n",
    "\n",
    "            dis_b3 = bernoulli.Bernoulli(attn3_p)\n",
    "            to_mask3 = 1 - dis_b3.sample().to(device)\n",
    "            mask3 = to_mask3.unsqueeze(1).repeat(1,input_dim,1).unsqueeze(1)\n",
    "\n",
    "\n",
    "            tempx, attn = attention(querys[3], keys[3], values[3], mask=mask3, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            self.mask = torch.cat((self.mask, mask3), 1)\n",
    "\n",
    "    #         attn4 = torch.mean(attn[0,0],0)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "    \n",
    "        \n",
    "\n",
    "        if self.training == False:\n",
    "# #             print(1)\n",
    "            \n",
    "            x, attn = attention(querys[0], keys[0], values[0], mask=None, \n",
    "                                     dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
    "\n",
    "\n",
    "            self.attn = attn\n",
    "\n",
    "            tempx, attn = attention(querys[1], keys[1], values[1], mask=None, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "\n",
    "\n",
    "            tempx, attn = attention(querys[2], keys[2], values[2], mask=None, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            tempx, attn = attention(querys[3], keys[3], values[3], mask=None, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "\n",
    "    #         attn4 = torch.mean(attn[0,0],0)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "        \n",
    "#         kl = nn.functional.kl_div(self.softmax(attn3).log(), self.softmax(attn4), size_average=None, reduce=None, reduction='mean') + \\\n",
    "#             nn.functional.kl_div(self.softmax(attn4).log(), self.softmax(attn3), size_average=None, reduce=None, reduction='mean')\n",
    "#         torch.nn.functional.kl_div(attn3, attn4, reduction='batchmean') + torch.nn.functional.kl_div(attn4, attn3, reduction='batchmean')\n",
    "\n",
    "        #Str DeCov\n",
    "        # DeCov_contexts = x.transpose(1, 2).transpose(0, 1).transpose(1, 2).transpose(2, 3)#d_input num_head d_v b (d_k) \n",
    "        # DeCov_between_loss = torch.tensor(0.0, dtype = torch.float32, device = device)\n",
    "        # DeCov_inside_loss = torch.tensor(0.0, dtype = torch.float32, device = device)\n",
    "        # for input_idx in range(input_dim):\n",
    "        #     current_input = DeCov_contexts[input_idx,:,:,:]\n",
    "        #     for i in range(self.h):\n",
    "        #         for j in range(self.h):\n",
    "        #             if i == j:\n",
    "        #                 covs = cov(current_input[i,:,:])\n",
    "        #                 DeCov_inside_loss += 0.5 * (torch.norm(covs, p = 'fro')**2)  \n",
    "        #                 #print(DeCov_inside_loss)\n",
    "        #             else:\n",
    "        #                 Vstack_context = torch.cat((current_input[i,:,:],current_input[j,:,:]) ,0)# 2*d_v b\n",
    "        #                 assert(Vstack_context.size(0) == 2*self.d_k)\n",
    "        #                 assert(Vstack_context.size(1) == nbatches)\n",
    "        #                 overflow_covs = cov(Vstack_context)[self.d_k:,:]\n",
    "        #                 covs = overflow_covs[:,:self.d_k]\n",
    "        #                 DeCov_between_loss += 0.5 * (torch.norm(covs, p = 'fro')**2) \n",
    "        #                 #print(DeCov_between_loss)\n",
    "        # DeCov_loss = DeCov_between_loss + 0.1 * DeCov_inside_loss\n",
    "        #print(DeCov_loss)\n",
    "\n",
    "\n",
    "      \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)# batch_size * d_input * hidden_dim\n",
    "\n",
    "        #DeCov \n",
    "#         DeCov_contexts = x.transpose(0, 1).transpose(1, 2) # I+1 H B\n",
    "# #         print(DeCov_contexts.shape)\n",
    "#         Covs = cov(DeCov_contexts[0,:,:])\n",
    "#         DeCov_loss = 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
    "#         for i in range(feature_dim -1+1):\n",
    "#             Covs = cov(DeCov_contexts[i+1,:,:])\n",
    "#             DeCov_loss += 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
    "\n",
    "#         print(DeCov_loss)\n",
    "#         print(kl)\n",
    "        \n",
    "        return self.final_linear(x), torch.zeros(1).to(device)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-7):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "def lNorm(x):\n",
    "    mean = x.mean(-1, keepdim=True)\n",
    "    std = x.std(-1, keepdim=True)\n",
    "    eps = 1e-7\n",
    "    return (x - mean) / (std + eps)\n",
    "\n",
    "def cov(m, y=None):\n",
    "    if y is not None:\n",
    "        m = torch.cat((m, y), dim=0)\n",
    "    m_exp = torch.mean(m, dim=1)\n",
    "    x = m - m_exp[:, None]\n",
    "    cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
    "    return cov\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        returned_value = sublayer(self.norm(x))\n",
    "        return x + self.dropout(returned_value[0]) , returned_value[1]\n",
    "\n",
    "class vanilla_transformer_encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(vanilla_transformer_encoder, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "#         self.Convs = clones(nn.Sequential(         \n",
    "#             nn.Conv1d(\n",
    "#                 in_channels=1,              # input height\n",
    "#                 out_channels=self.hidden_dim,            # n_filters\n",
    "#                 kernel_size=4,              # filter size\n",
    "#                 stride=1,                   # filter movement/step\n",
    "# #                 padding=2, \n",
    "# #                 dilation = 2,# if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "#             ),                              # output shape (16, 28, 28)\n",
    "#             nn.ReLU(),                      # activation\n",
    "#           nn.MaxPool1d(1000, stride=None)\n",
    "            \n",
    "#         ), self.input_dim)\n",
    "        \n",
    "#         self.DConvs = clones(nn.Sequential(         \n",
    "#             nn.Conv1d(\n",
    "#                 in_channels=1,              # input height\n",
    "#                 out_channels=self.hidden_dim,            # n_filters\n",
    "#                 kernel_size=4,\n",
    "#                 dilation = 2,# filter size\n",
    "#                 stride=1,                   # filter movement/step\n",
    "# #                 padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "#             ),                              # output shape (16, 28, 28)\n",
    "#             nn.ReLU(),                      # activation\n",
    "#           nn.MaxPool1d(1000, stride=None)\n",
    "            \n",
    "#         ), self.input_dim)\n",
    "        \n",
    "        \n",
    "#         self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='concat', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
    "        \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, lens):\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "#         demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "     \n",
    "        GRU_embeded_input = self.GRUs[0](pack_padded_sequence(input[:,:,0].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.GRUs[i+1](pack_padded_sequence(input[:,:,i+1].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "            GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
    "            \n",
    "#         Conv_embeded_input = self.Convs[0](input[:,:,0].unsqueeze(1)).squeeze(-1).unsqueeze(1) # b 1 h\n",
    "# #         print(Conv_embeded_input.shape)\n",
    "#         for i in range(feature_dim-1):\n",
    "#             embeded_input = self.Convs[i+1](input[:,:,i+1].unsqueeze(1)).squeeze(-1).unsqueeze(1) # b 1 h\n",
    "#             Conv_embeded_input = torch.cat((Conv_embeded_input, embeded_input), 1)\n",
    "        \n",
    "# # #         print(GRU_embeded_input.shape)\n",
    "# # #         print(Conv_embeded_input.shape)\n",
    "#         GRU_embeded_input = torch.cat((GRU_embeded_input, Conv_embeded_input), 1)# b i+1 h\n",
    "    \n",
    "#         Conv_embeded_input = self.DConvs[0](input[:,:,0].unsqueeze(1)).squeeze(-1).unsqueeze(1) # b 1 h\n",
    "# #         print(Conv_embeded_input.shape)\n",
    "#         for i in range(feature_dim-1):\n",
    "#             embeded_input = self.DConvs[i+1](input[:,:,i+1].unsqueeze(1)).squeeze(-1).unsqueeze(1) # b 1 h\n",
    "#             Conv_embeded_input = torch.cat((Conv_embeded_input, embeded_input), 1)\n",
    "            \n",
    "#         GRU_embeded_input = torch.cat((GRU_embeded_input, Conv_embeded_input), 1)# b i+1 h\n",
    "            \n",
    "#         print( GRU_embeded_input.shape)\n",
    "#         GRU_embeded_input =  Conv_embeded_input\n",
    "\n",
    "#         GRU_embeded_input = torch.cat((GRU_embeded_input, demo_main), 1)# b i+1 h\n",
    "        posi_input = self.dropout( GRU_embeded_input) # batch_size * d_input * hidden_dim\n",
    "\n",
    "\n",
    "        #mask = subsequent_mask(time_step).to(device) # 1 t t 下三角 N to 1任务不用mask\n",
    "        contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "    \n",
    "        DeCov_loss = contexts[1]\n",
    "        contexts = contexts[0]\n",
    "\n",
    "        contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "        #contexts = contexts.view(batch_size, feature_dim * self.hidden_dim)#\n",
    "        # contexts = torch.matmul(self.Wproj, contexts) + self.bproj\n",
    "        # contexts = contexts.squeeze()\n",
    "        # demo_key = self.demo_proj(demo_input)# b hidden_dim\n",
    "        # demo_key = self.relu(demo_key)\n",
    "        # input_dim_scores = torch.matmul(contexts, demo_key.unsqueeze(-1)).squeeze() # b i\n",
    "        # input_dim_scores = self.dropout(self.sigmoid(input_dim_scores)).unsqueeze(1)# b i\n",
    "        \n",
    "        # weighted_contexts = torch.matmul(input_dim_scores, contexts).squeeze()\n",
    "#         print(contexts.shape)\n",
    "\n",
    "        weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
    "        output = self.output(self.dropout(weighted_contexts))# b 1\n",
    "        output = self.sigmoid(output)\n",
    "#         print(weighted_contexts.shape)\n",
    "          \n",
    "        return output, DeCov_loss  ,weighted_contexts\n",
    "    #, self.MultiHeadedAttention.attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:25:40.167188Z",
     "start_time": "2021-10-04T14:25:36.068306Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED) #numpy\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED) # cpu\n",
    "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "    \n",
    "epochs = 150\n",
    "batch_size = 256\n",
    "input_dim = 33\n",
    "hidden_dim = 32\n",
    "d_model = 32\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1\n",
    "\n",
    "model = vanilla_transformer_encoder(input_dim = input_dim, hidden_dim = hidden_dim, d_model = d_model,  MHD_num_head = MHD_num_head , d_ff = d_ff, output_dim = output_dim).to(device)\n",
    "# input_dim, d_model, d_k, d_v, MHD_num_head, d_ff, output_dim\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T21:05:15.968123Z",
     "start_time": "2021-10-04T14:25:40.169266Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 0: Train Loss = 0.6265\n",
      "Epoch 0 Batch 20: Train Loss = 0.3715\n",
      "Epoch 0 Batch 40: Train Loss = 0.3228\n",
      "Epoch 0 Batch 60: Train Loss = 0.3644\n",
      "Epoch 0 Batch 80: Train Loss = 0.2476\n",
      "Epoch 0 Batch 100: Train Loss = 0.2662\n",
      "Epoch 0 Batch 120: Train Loss = 0.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1]) # TP/TP+FP = PPV = precision\n",
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1]) # TP/TP+FP = PPV = precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.3022 Valid loss = 0.2574 roc = 0.7286\n",
      "confusion matrix:\n",
      "[[3918    0]\n",
      " [ 308    0]]\n",
      "accuracy = 0.9271178245544434\n",
      "precision class 0 = 0.9271178245544434\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7285749918789735\n",
      "AUC of PRC = 0.2356456412611008\n",
      "min(+P, Se) = 0.3215434083601286\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7286 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0: Train Loss = 0.2745\n",
      "Epoch 1 Batch 20: Train Loss = 0.2490\n",
      "Epoch 1 Batch 40: Train Loss = 0.2557\n",
      "Epoch 1 Batch 60: Train Loss = 0.2180\n",
      "Epoch 1 Batch 80: Train Loss = 0.2775\n",
      "Epoch 1 Batch 100: Train Loss = 0.2311\n",
      "Epoch 1 Batch 120: Train Loss = 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1]) # TP/TP+FP = PPV = precision\n",
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1]) # TP/TP+FP = PPV = precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.2648 Valid loss = 0.2420 roc = 0.7468\n",
      "confusion matrix:\n",
      "[[3918    0]\n",
      " [ 308    0]]\n",
      "accuracy = 0.9271178245544434\n",
      "precision class 0 = 0.9271178245544434\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7467747923337509\n",
      "AUC of PRC = 0.17764010601727653\n",
      "min(+P, Se) = 0.22727272727272727\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7468 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 0: Train Loss = 0.2888\n",
      "Epoch 2 Batch 20: Train Loss = 0.2052\n",
      "Epoch 2 Batch 40: Train Loss = 0.3248\n",
      "Epoch 2 Batch 60: Train Loss = 0.3034\n",
      "Epoch 2 Batch 80: Train Loss = 0.2710\n",
      "Epoch 2 Batch 100: Train Loss = 0.1589\n",
      "Epoch 2 Batch 120: Train Loss = 0.2242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score=2*prec1*rec1/(prec1+rec1)\n",
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score=2*prec1*rec1/(prec1+rec1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.2490 Valid loss = 0.2191 roc = 0.8025\n",
      "confusion matrix:\n",
      "[[3917    1]\n",
      " [ 308    0]]\n",
      "accuracy = 0.9268811941146851\n",
      "precision class 0 = 0.9271005988121033\n",
      "precision class 1 = 0.0\n",
      "recall class 0 = 0.9997447729110718\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.8025388980595719\n",
      "AUC of PRC = 0.28106491088960783\n",
      "min(+P, Se) = 0.3225806451612903\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.8025 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 0: Train Loss = 0.2722\n",
      "Epoch 3 Batch 20: Train Loss = 0.2065\n",
      "Epoch 3 Batch 40: Train Loss = 0.3293\n",
      "Epoch 3 Batch 60: Train Loss = 0.2442\n",
      "Epoch 3 Batch 80: Train Loss = 0.2370\n",
      "Epoch 3 Batch 100: Train Loss = 0.1981\n",
      "Epoch 3 Batch 120: Train Loss = 0.2377\n",
      "Epoch 3: Loss = 0.2262 Valid loss = 0.1981 roc = 0.8397\n",
      "confusion matrix:\n",
      "[[3903   15]\n",
      " [ 265   43]]\n",
      "accuracy = 0.9337434768676758\n",
      "precision class 0 = 0.9364203214645386\n",
      "precision class 1 = 0.7413793206214905\n",
      "recall class 0 = 0.9961715340614319\n",
      "recall class 1 = 0.1396103948354721\n",
      "AUC of ROC = 0.8397497729427285\n",
      "AUC of PRC = 0.40014293051428473\n",
      "min(+P, Se) = 0.41883116883116883\n",
      "f1_score = 0.23497268153794643\n",
      "------------ Save best model - AUROC: 0.8397 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 0: Train Loss = 0.2271\n",
      "Epoch 4 Batch 20: Train Loss = 0.2330\n",
      "Epoch 4 Batch 40: Train Loss = 0.1824\n",
      "Epoch 4 Batch 60: Train Loss = 0.2075\n",
      "Epoch 4 Batch 80: Train Loss = 0.2044\n",
      "Epoch 4 Batch 100: Train Loss = 0.2025\n",
      "Epoch 4 Batch 120: Train Loss = 0.2531\n",
      "Epoch 4: Loss = 0.2117 Valid loss = 0.1837 roc = 0.8674\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 229   79]]\n",
      "accuracy = 0.9361097812652588\n",
      "precision class 0 = 0.944227933883667\n",
      "precision class 1 = 0.6583333611488342\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.2564935088157654\n",
      "AUC of ROC = 0.867429214481282\n",
      "AUC of PRC = 0.47391773293585915\n",
      "min(+P, Se) = 0.4855305466237942\n",
      "f1_score = 0.36915888528301566\n",
      "------------ Save best model - AUROC: 0.8674 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 0: Train Loss = 0.1829\n",
      "Epoch 5 Batch 20: Train Loss = 0.1854\n",
      "Epoch 5 Batch 40: Train Loss = 0.1737\n",
      "Epoch 5 Batch 60: Train Loss = 0.2286\n",
      "Epoch 5 Batch 80: Train Loss = 0.1387\n",
      "Epoch 5 Batch 100: Train Loss = 0.1525\n",
      "Epoch 5 Batch 120: Train Loss = 0.1788\n",
      "Epoch 5: Loss = 0.1827 Valid loss = 0.1594 roc = 0.9086\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 158  150]]\n",
      "accuracy = 0.9540936946868896\n",
      "precision class 0 = 0.96089106798172\n",
      "precision class 1 = 0.8064516186714172\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.48701298236846924\n",
      "AUC of ROC = 0.9085812732443667\n",
      "AUC of PRC = 0.6641758409607632\n",
      "min(+P, Se) = 0.6298701298701299\n",
      "f1_score = 0.6072874194326091\n",
      "------------ Save best model - AUROC: 0.9086 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 0: Train Loss = 0.1491\n",
      "Epoch 6 Batch 20: Train Loss = 0.2379\n",
      "Epoch 6 Batch 40: Train Loss = 0.2134\n",
      "Epoch 6 Batch 60: Train Loss = 0.2084\n",
      "Epoch 6 Batch 80: Train Loss = 0.1245\n",
      "Epoch 6 Batch 100: Train Loss = 0.1948\n",
      "Epoch 6 Batch 120: Train Loss = 0.1273\n",
      "Epoch 6: Loss = 0.1631 Valid loss = 0.1517 roc = 0.9136\n",
      "confusion matrix:\n",
      "[[3868   50]\n",
      " [ 146  162]]\n",
      "accuracy = 0.953620433807373\n",
      "precision class 0 = 0.963627278804779\n",
      "precision class 1 = 0.7641509175300598\n",
      "recall class 0 = 0.9872384071350098\n",
      "recall class 1 = 0.5259740352630615\n",
      "AUC of ROC = 0.9135657604264036\n",
      "AUC of PRC = 0.6706942815569269\n",
      "min(+P, Se) = 0.6331168831168831\n",
      "f1_score = 0.6230769497826266\n",
      "------------ Save best model - AUROC: 0.9136 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 0: Train Loss = 0.1430\n",
      "Epoch 7 Batch 20: Train Loss = 0.1622\n",
      "Epoch 7 Batch 40: Train Loss = 0.1986\n",
      "Epoch 7 Batch 60: Train Loss = 0.1083\n",
      "Epoch 7 Batch 80: Train Loss = 0.1696\n",
      "Epoch 7 Batch 100: Train Loss = 0.1849\n",
      "Epoch 7 Batch 120: Train Loss = 0.1183\n",
      "Epoch 7: Loss = 0.1566 Valid loss = 0.1431 roc = 0.9185\n",
      "confusion matrix:\n",
      "[[3862   56]\n",
      " [ 139  169]]\n",
      "accuracy = 0.9538570642471313\n",
      "precision class 0 = 0.9652586579322815\n",
      "precision class 1 = 0.7511110901832581\n",
      "recall class 0 = 0.9857069849967957\n",
      "recall class 1 = 0.548701286315918\n",
      "AUC of ROC = 0.9185436181990546\n",
      "AUC of PRC = 0.6867077693555373\n",
      "min(+P, Se) = 0.6590909090909091\n",
      "f1_score = 0.6341463548127717\n",
      "------------ Save best model - AUROC: 0.9185 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 0: Train Loss = 0.1278\n",
      "Epoch 8 Batch 20: Train Loss = 0.2008\n",
      "Epoch 8 Batch 40: Train Loss = 0.1550\n",
      "Epoch 8 Batch 60: Train Loss = 0.1755\n",
      "Epoch 8 Batch 80: Train Loss = 0.1545\n",
      "Epoch 8 Batch 100: Train Loss = 0.1451\n",
      "Epoch 8 Batch 120: Train Loss = 0.1626\n",
      "Epoch 8: Loss = 0.1497 Valid loss = 0.1424 roc = 0.9185\n",
      "confusion matrix:\n",
      "[[3862   56]\n",
      " [ 138  170]]\n",
      "accuracy = 0.9540936946868896\n",
      "precision class 0 = 0.965499997138977\n",
      "precision class 1 = 0.752212405204773\n",
      "recall class 0 = 0.9857069849967957\n",
      "recall class 1 = 0.551948070526123\n",
      "AUC of ROC = 0.9184677943292032\n",
      "AUC of PRC = 0.6900769276304592\n",
      "min(+P, Se) = 0.6493506493506493\n",
      "f1_score = 0.6367041378798209\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 0: Train Loss = 0.1067\n",
      "Epoch 9 Batch 20: Train Loss = 0.1501\n",
      "Epoch 9 Batch 40: Train Loss = 0.1510\n",
      "Epoch 9 Batch 60: Train Loss = 0.1353\n",
      "Epoch 9 Batch 80: Train Loss = 0.1316\n",
      "Epoch 9 Batch 100: Train Loss = 0.1768\n",
      "Epoch 9 Batch 120: Train Loss = 0.1540\n",
      "Epoch 9: Loss = 0.1493 Valid loss = 0.1462 roc = 0.9175\n",
      "confusion matrix:\n",
      "[[3854   64]\n",
      " [ 143  165]]\n",
      "accuracy = 0.9510174989700317\n",
      "precision class 0 = 0.9642231464385986\n",
      "precision class 1 = 0.72052401304245\n",
      "recall class 0 = 0.9836651086807251\n",
      "recall class 1 = 0.5357142686843872\n",
      "AUC of ROC = 0.9174539090312444\n",
      "AUC of PRC = 0.6695888623365874\n",
      "min(+P, Se) = 0.6198083067092651\n",
      "f1_score = 0.6145251560082381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 0: Train Loss = 0.1072\n",
      "Epoch 10 Batch 20: Train Loss = 0.1250\n",
      "Epoch 10 Batch 40: Train Loss = 0.1504\n",
      "Epoch 10 Batch 60: Train Loss = 0.1533\n",
      "Epoch 10 Batch 80: Train Loss = 0.1435\n",
      "Epoch 10 Batch 100: Train Loss = 0.1011\n",
      "Epoch 10 Batch 120: Train Loss = 0.1236\n",
      "Epoch 10: Loss = 0.1525 Valid loss = 0.1466 roc = 0.9237\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 144  164]]\n",
      "accuracy = 0.9548035860061646\n",
      "precision class 0 = 0.9641345143318176\n",
      "precision class 1 = 0.7772511839866638\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.5324675440788269\n",
      "AUC of ROC = 0.9236772670922747\n",
      "AUC of PRC = 0.6769610602524303\n",
      "min(+P, Se) = 0.6266233766233766\n",
      "f1_score = 0.6319845936402381\n",
      "------------ Save best model - AUROC: 0.9237 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 0: Train Loss = 0.1287\n",
      "Epoch 11 Batch 20: Train Loss = 0.1590\n",
      "Epoch 11 Batch 40: Train Loss = 0.1330\n",
      "Epoch 11 Batch 60: Train Loss = 0.1583\n",
      "Epoch 11 Batch 80: Train Loss = 0.1352\n",
      "Epoch 11 Batch 100: Train Loss = 0.2179\n",
      "Epoch 11 Batch 120: Train Loss = 0.1631\n",
      "Epoch 11: Loss = 0.1483 Valid loss = 0.1514 roc = 0.9269\n",
      "confusion matrix:\n",
      "[[3803  115]\n",
      " [ 108  200]]\n",
      "accuracy = 0.9472314119338989\n",
      "precision class 0 = 0.972385585308075\n",
      "precision class 1 = 0.6349206566810608\n",
      "recall class 0 = 0.9706482887268066\n",
      "recall class 1 = 0.649350643157959\n",
      "AUC of ROC = 0.9268842438827125\n",
      "AUC of PRC = 0.6922088208716644\n",
      "min(+P, Se) = 0.635483870967742\n",
      "f1_score = 0.6420546125363358\n",
      "------------ Save best model - AUROC: 0.9269 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 0: Train Loss = 0.1568\n",
      "Epoch 12 Batch 20: Train Loss = 0.1541\n",
      "Epoch 12 Batch 40: Train Loss = 0.1563\n",
      "Epoch 12 Batch 60: Train Loss = 0.1420\n",
      "Epoch 12 Batch 80: Train Loss = 0.1958\n",
      "Epoch 12 Batch 100: Train Loss = 0.1411\n",
      "Epoch 12 Batch 120: Train Loss = 0.1678\n",
      "Epoch 12: Loss = 0.1457 Valid loss = 0.1401 roc = 0.9294\n",
      "confusion matrix:\n",
      "[[3857   61]\n",
      " [ 132  176]]\n",
      "accuracy = 0.954330325126648\n",
      "precision class 0 = 0.9669089913368225\n",
      "precision class 1 = 0.7426160573959351\n",
      "recall class 0 = 0.9844308495521545\n",
      "recall class 1 = 0.5714285969734192\n",
      "AUC of ROC = 0.9293586709360064\n",
      "AUC of PRC = 0.7009065433185688\n",
      "min(+P, Se) = 0.6666666666666666\n",
      "f1_score = 0.6458715555947024\n",
      "------------ Save best model - AUROC: 0.9294 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 0: Train Loss = 0.0932\n",
      "Epoch 13 Batch 20: Train Loss = 0.1678\n",
      "Epoch 13 Batch 40: Train Loss = 0.1095\n",
      "Epoch 13 Batch 60: Train Loss = 0.1553\n",
      "Epoch 13 Batch 80: Train Loss = 0.1784\n",
      "Epoch 13 Batch 100: Train Loss = 0.1466\n",
      "Epoch 13 Batch 120: Train Loss = 0.0781\n",
      "Epoch 13: Loss = 0.1392 Valid loss = 0.1402 roc = 0.9298\n",
      "confusion matrix:\n",
      "[[3856   62]\n",
      " [ 135  173]]\n",
      "accuracy = 0.9533838033676147\n",
      "precision class 0 = 0.9661738872528076\n",
      "precision class 1 = 0.73617023229599\n",
      "recall class 0 = 0.9841756224632263\n",
      "recall class 1 = 0.5616883039474487\n",
      "AUC of ROC = 0.9297937259269572\n",
      "AUC of PRC = 0.7039812529268287\n",
      "min(+P, Se) = 0.6590909090909091\n",
      "f1_score = 0.6372007682468053\n",
      "------------ Save best model - AUROC: 0.9298 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 0: Train Loss = 0.1868\n",
      "Epoch 14 Batch 20: Train Loss = 0.1074\n",
      "Epoch 14 Batch 40: Train Loss = 0.1116\n",
      "Epoch 14 Batch 60: Train Loss = 0.1062\n",
      "Epoch 14 Batch 80: Train Loss = 0.1334\n",
      "Epoch 14 Batch 100: Train Loss = 0.1437\n",
      "Epoch 14 Batch 120: Train Loss = 0.1383\n",
      "Epoch 14: Loss = 0.1411 Valid loss = 0.1362 roc = 0.9320\n",
      "confusion matrix:\n",
      "[[3837   81]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9533838033676147\n",
      "precision class 0 = 0.9706552028656006\n",
      "precision class 1 = 0.7032967209815979\n",
      "recall class 0 = 0.9793261885643005\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9320294942423579\n",
      "AUC of PRC = 0.711304642181418\n",
      "min(+P, Se) = 0.6785714285714286\n",
      "f1_score = 0.6609294608155335\n",
      "------------ Save best model - AUROC: 0.9320 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 0: Train Loss = 0.1289\n",
      "Epoch 15 Batch 20: Train Loss = 0.1787\n",
      "Epoch 15 Batch 40: Train Loss = 0.1189\n",
      "Epoch 15 Batch 60: Train Loss = 0.1469\n",
      "Epoch 15 Batch 80: Train Loss = 0.1775\n",
      "Epoch 15 Batch 100: Train Loss = 0.1289\n",
      "Epoch 15 Batch 120: Train Loss = 0.1314\n",
      "Epoch 15: Loss = 0.1396 Valid loss = 0.1369 roc = 0.9348\n",
      "confusion matrix:\n",
      "[[3831   87]\n",
      " [ 110  198]]\n",
      "accuracy = 0.9533838033676147\n",
      "precision class 0 = 0.9720882773399353\n",
      "precision class 1 = 0.6947368383407593\n",
      "recall class 0 = 0.9777947664260864\n",
      "recall class 1 = 0.6428571343421936\n",
      "AUC of ROC = 0.9348047307465379\n",
      "AUC of PRC = 0.7174450133480725\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6677908576698386\n",
      "------------ Save best model - AUROC: 0.9348 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 0: Train Loss = 0.1680\n",
      "Epoch 16 Batch 20: Train Loss = 0.1298\n",
      "Epoch 16 Batch 40: Train Loss = 0.1923\n",
      "Epoch 16 Batch 60: Train Loss = 0.1293\n",
      "Epoch 16 Batch 80: Train Loss = 0.1589\n",
      "Epoch 16 Batch 100: Train Loss = 0.2121\n",
      "Epoch 16 Batch 120: Train Loss = 0.1385\n",
      "Epoch 16: Loss = 0.1437 Valid loss = 0.1400 roc = 0.9321\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 135  173]]\n",
      "accuracy = 0.9552768468856812\n",
      "precision class 0 = 0.9662415385246277\n",
      "precision class 1 = 0.7621145248413086\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.5616883039474487\n",
      "AUC of ROC = 0.9321339074401862\n",
      "AUC of PRC = 0.7034238466526669\n",
      "min(+P, Se) = 0.6601941747572816\n",
      "f1_score = 0.6467289622934305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 0: Train Loss = 0.1078\n",
      "Epoch 17 Batch 20: Train Loss = 0.1172\n",
      "Epoch 17 Batch 40: Train Loss = 0.1589\n",
      "Epoch 17 Batch 60: Train Loss = 0.2426\n",
      "Epoch 17 Batch 80: Train Loss = 0.1268\n",
      "Epoch 17 Batch 100: Train Loss = 0.1777\n",
      "Epoch 17 Batch 120: Train Loss = 0.1656\n",
      "Epoch 17: Loss = 0.1385 Valid loss = 0.1347 roc = 0.9353\n",
      "confusion matrix:\n",
      "[[3858   60]\n",
      " [ 123  185]]\n",
      "accuracy = 0.956696629524231\n",
      "precision class 0 = 0.969103217124939\n",
      "precision class 1 = 0.7551020383834839\n",
      "recall class 0 = 0.9846860766410828\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.935330940116545\n",
      "AUC of PRC = 0.7206519586657855\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.669077760572331\n",
      "------------ Save best model - AUROC: 0.9353 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 0: Train Loss = 0.1209\n",
      "Epoch 18 Batch 20: Train Loss = 0.1225\n",
      "Epoch 18 Batch 40: Train Loss = 0.2080\n",
      "Epoch 18 Batch 60: Train Loss = 0.1136\n",
      "Epoch 18 Batch 80: Train Loss = 0.1543\n",
      "Epoch 18 Batch 100: Train Loss = 0.1124\n",
      "Epoch 18 Batch 120: Train Loss = 0.1394\n",
      "Epoch 18: Loss = 0.1366 Valid loss = 0.1348 roc = 0.9369\n",
      "confusion matrix:\n",
      "[[3858   60]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9550402164459229\n",
      "precision class 0 = 0.9674022197723389\n",
      "precision class 1 = 0.7478991746902466\n",
      "recall class 0 = 0.9846860766410828\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.936934428511764\n",
      "AUC of PRC = 0.7255998932002403\n",
      "min(+P, Se) = 0.6753246753246753\n",
      "f1_score = 0.6520146754601532\n",
      "------------ Save best model - AUROC: 0.9369 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 0: Train Loss = 0.0569\n",
      "Epoch 19 Batch 20: Train Loss = 0.1234\n",
      "Epoch 19 Batch 40: Train Loss = 0.1725\n",
      "Epoch 19 Batch 60: Train Loss = 0.1053\n",
      "Epoch 19 Batch 80: Train Loss = 0.1344\n",
      "Epoch 19 Batch 100: Train Loss = 0.0983\n",
      "Epoch 19 Batch 120: Train Loss = 0.1040\n",
      "Epoch 19: Loss = 0.1351 Valid loss = 0.1288 roc = 0.9390\n",
      "confusion matrix:\n",
      "[[3853   65]\n",
      " [ 119  189]]\n",
      "accuracy = 0.9564599990844727\n",
      "precision class 0 = 0.9700402617454529\n",
      "precision class 1 = 0.7440944910049438\n",
      "recall class 0 = 0.9834098815917969\n",
      "recall class 1 = 0.6136363744735718\n",
      "AUC of ROC = 0.9389936888022646\n",
      "AUC of PRC = 0.7347812300578436\n",
      "min(+P, Se) = 0.6785714285714286\n",
      "f1_score = 0.672597872429021\n",
      "------------ Save best model - AUROC: 0.9390 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 0: Train Loss = 0.0987\n",
      "Epoch 20 Batch 20: Train Loss = 0.1051\n",
      "Epoch 20 Batch 40: Train Loss = 0.1230\n",
      "Epoch 20 Batch 60: Train Loss = 0.1550\n",
      "Epoch 20 Batch 80: Train Loss = 0.1553\n",
      "Epoch 20 Batch 100: Train Loss = 0.1626\n",
      "Epoch 20 Batch 120: Train Loss = 0.1295\n",
      "Epoch 20: Loss = 0.1338 Valid loss = 0.1446 roc = 0.9276\n",
      "confusion matrix:\n",
      "[[3837   81]\n",
      " [ 134  174]]\n",
      "accuracy = 0.9491244554519653\n",
      "precision class 0 = 0.9662553668022156\n",
      "precision class 1 = 0.6823529601097107\n",
      "recall class 0 = 0.9793261885643005\n",
      "recall class 1 = 0.5649350881576538\n",
      "AUC of ROC = 0.9276499406667861\n",
      "AUC of PRC = 0.6759211060533935\n",
      "min(+P, Se) = 0.6103896103896104\n",
      "f1_score = 0.6181172803363776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 0: Train Loss = 0.1353\n",
      "Epoch 21 Batch 20: Train Loss = 0.1557\n",
      "Epoch 21 Batch 40: Train Loss = 0.1086\n",
      "Epoch 21 Batch 60: Train Loss = 0.1421\n",
      "Epoch 21 Batch 80: Train Loss = 0.1449\n",
      "Epoch 21 Batch 100: Train Loss = 0.0920\n",
      "Epoch 21 Batch 120: Train Loss = 0.2004\n",
      "Epoch 21: Loss = 0.1376 Valid loss = 0.1268 roc = 0.9401\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.9677338600158691\n",
      "precision class 1 = 0.7850877046585083\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9401140589884847\n",
      "AUC of PRC = 0.7376179335189651\n",
      "min(+P, Se) = 0.6881028938906752\n",
      "f1_score = 0.667910471090525\n",
      "------------ Save best model - AUROC: 0.9401 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 0: Train Loss = 0.2262\n",
      "Epoch 22 Batch 20: Train Loss = 0.1252\n",
      "Epoch 22 Batch 40: Train Loss = 0.1284\n",
      "Epoch 22 Batch 60: Train Loss = 0.1210\n",
      "Epoch 22 Batch 80: Train Loss = 0.1924\n",
      "Epoch 22 Batch 100: Train Loss = 0.0855\n",
      "Epoch 22 Batch 120: Train Loss = 0.1345\n",
      "Epoch 22: Loss = 0.1355 Valid loss = 0.1239 roc = 0.9416\n",
      "confusion matrix:\n",
      "[[3859   59]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9569332599639893\n",
      "precision class 0 = 0.9691110253334045\n",
      "precision class 1 = 0.7581967115402222\n",
      "recall class 0 = 0.984941303730011\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.941560098910788\n",
      "AUC of PRC = 0.7415094158463178\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6702898551100217\n",
      "------------ Save best model - AUROC: 0.9416 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 0: Train Loss = 0.1453\n",
      "Epoch 23 Batch 20: Train Loss = 0.1609\n",
      "Epoch 23 Batch 40: Train Loss = 0.1506\n",
      "Epoch 23 Batch 60: Train Loss = 0.0715\n",
      "Epoch 23 Batch 80: Train Loss = 0.1305\n",
      "Epoch 23 Batch 100: Train Loss = 0.0976\n",
      "Epoch 23 Batch 120: Train Loss = 0.1896\n",
      "Epoch 23: Loss = 0.1368 Valid loss = 0.1250 roc = 0.9402\n",
      "confusion matrix:\n",
      "[[3858   60]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.9703219532966614\n",
      "precision class 1 = 0.7599999904632568\n",
      "recall class 0 = 0.9846860766410828\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9402068707198876\n",
      "AUC of PRC = 0.7419193633951998\n",
      "min(+P, Se) = 0.686084142394822\n",
      "f1_score = 0.6810035990323491\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 0: Train Loss = 0.0978\n",
      "Epoch 24 Batch 20: Train Loss = 0.1307\n",
      "Epoch 24 Batch 40: Train Loss = 0.1372\n",
      "Epoch 24 Batch 60: Train Loss = 0.1577\n",
      "Epoch 24 Batch 80: Train Loss = 0.1710\n",
      "Epoch 24 Batch 100: Train Loss = 0.1183\n",
      "Epoch 24 Batch 120: Train Loss = 0.1094\n",
      "Epoch 24: Loss = 0.1321 Valid loss = 0.1249 roc = 0.9403\n",
      "confusion matrix:\n",
      "[[3878   40]\n",
      " [ 134  174]]\n",
      "accuracy = 0.9588263034820557\n",
      "precision class 0 = 0.9666001796722412\n",
      "precision class 1 = 0.8130841255187988\n",
      "recall class 0 = 0.9897907376289368\n",
      "recall class 1 = 0.5649350881576538\n",
      "AUC of ROC = 0.9402657067281877\n",
      "AUC of PRC = 0.7462630917684218\n",
      "min(+P, Se) = 0.6881028938906752\n",
      "f1_score = 0.66666668733024\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 0: Train Loss = 0.0847\n",
      "Epoch 25 Batch 20: Train Loss = 0.1056\n",
      "Epoch 25 Batch 40: Train Loss = 0.1425\n",
      "Epoch 25 Batch 60: Train Loss = 0.0673\n",
      "Epoch 25 Batch 80: Train Loss = 0.1358\n",
      "Epoch 25 Batch 100: Train Loss = 0.1216\n",
      "Epoch 25 Batch 120: Train Loss = 0.0892\n",
      "Epoch 25: Loss = 0.1342 Valid loss = 0.1363 roc = 0.9358\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 134  174]]\n",
      "accuracy = 0.9555134773254395\n",
      "precision class 0 = 0.9664832353591919\n",
      "precision class 1 = 0.7631579041481018\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.5649350881576538\n",
      "AUC of ROC = 0.9358223450872762\n",
      "AUC of PRC = 0.7254356389910742\n",
      "min(+P, Se) = 0.6688311688311688\n",
      "f1_score = 0.6492537209466624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 0: Train Loss = 0.1768\n",
      "Epoch 26 Batch 20: Train Loss = 0.1327\n",
      "Epoch 26 Batch 40: Train Loss = 0.1200\n",
      "Epoch 26 Batch 60: Train Loss = 0.1174\n",
      "Epoch 26 Batch 80: Train Loss = 0.0889\n",
      "Epoch 26 Batch 100: Train Loss = 0.0941\n",
      "Epoch 26 Batch 120: Train Loss = 0.1250\n",
      "Epoch 26: Loss = 0.1299 Valid loss = 0.1226 roc = 0.9424\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 131  177]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9673316478729248\n",
      "precision class 1 = 0.8194444179534912\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.5746753215789795\n",
      "AUC of ROC = 0.9423904324363743\n",
      "AUC of PRC = 0.7515260826452994\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6755725079417457\n",
      "------------ Save best model - AUROC: 0.9424 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 0: Train Loss = 0.0866\n",
      "Epoch 27 Batch 20: Train Loss = 0.1113\n",
      "Epoch 27 Batch 40: Train Loss = 0.1819\n",
      "Epoch 27 Batch 60: Train Loss = 0.0968\n",
      "Epoch 27 Batch 80: Train Loss = 0.1003\n",
      "Epoch 27 Batch 100: Train Loss = 0.1765\n",
      "Epoch 27 Batch 120: Train Loss = 0.1436\n",
      "Epoch 27: Loss = 0.1316 Valid loss = 0.1234 roc = 0.9419\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 139  169]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.9654057025909424\n",
      "precision class 1 = 0.8125\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.548701286315918\n",
      "AUC of ROC = 0.9418509642475952\n",
      "AUC of PRC = 0.7470528400063957\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6550387508643803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 0: Train Loss = 0.1914\n",
      "Epoch 28 Batch 20: Train Loss = 0.1291\n",
      "Epoch 28 Batch 40: Train Loss = 0.0893\n",
      "Epoch 28 Batch 60: Train Loss = 0.1150\n",
      "Epoch 28 Batch 80: Train Loss = 0.0947\n",
      "Epoch 28 Batch 100: Train Loss = 0.1422\n",
      "Epoch 28 Batch 120: Train Loss = 0.0930\n",
      "Epoch 28: Loss = 0.1294 Valid loss = 0.1213 roc = 0.9405\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9692038297653198\n",
      "precision class 1 = 0.7974137663841248\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9404944213520017\n",
      "AUC of PRC = 0.7537272397594755\n",
      "min(+P, Se) = 0.6891025641025641\n",
      "f1_score = 0.6851851501386359\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 0: Train Loss = 0.0960\n",
      "Epoch 29 Batch 20: Train Loss = 0.1072\n",
      "Epoch 29 Batch 40: Train Loss = 0.1129\n",
      "Epoch 29 Batch 60: Train Loss = 0.1670\n",
      "Epoch 29 Batch 80: Train Loss = 0.1704\n",
      "Epoch 29 Batch 100: Train Loss = 0.1857\n",
      "Epoch 29 Batch 120: Train Loss = 0.0862\n",
      "Epoch 29: Loss = 0.1293 Valid loss = 0.1334 roc = 0.9315\n",
      "confusion matrix:\n",
      "[[3866   52]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9588263034820557\n",
      "precision class 0 = 0.9694082140922546\n",
      "precision class 1 = 0.7815126180648804\n",
      "recall class 0 = 0.9867278933525085\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.931507428253217\n",
      "AUC of PRC = 0.7280595176982216\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6813187012932637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 0: Train Loss = 0.1212\n",
      "Epoch 30 Batch 20: Train Loss = 0.1188\n",
      "Epoch 30 Batch 40: Train Loss = 0.0796\n",
      "Epoch 30 Batch 60: Train Loss = 0.1519\n",
      "Epoch 30 Batch 80: Train Loss = 0.1085\n",
      "Epoch 30 Batch 100: Train Loss = 0.1302\n",
      "Epoch 30 Batch 120: Train Loss = 0.1259\n",
      "Epoch 30: Loss = 0.1298 Valid loss = 0.1210 roc = 0.9430\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9687265157699585\n",
      "precision class 1 = 0.7991266250610352\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.9429887366334533\n",
      "AUC of PRC = 0.7525605022796744\n",
      "min(+P, Se) = 0.6935483870967742\n",
      "f1_score = 0.6815642729698778\n",
      "------------ Save best model - AUROC: 0.9430 ------------\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 0: Train Loss = 0.1022\n",
      "Epoch 31 Batch 20: Train Loss = 0.1736\n",
      "Epoch 31 Batch 40: Train Loss = 0.1145\n",
      "Epoch 31 Batch 60: Train Loss = 0.1131\n",
      "Epoch 31 Batch 80: Train Loss = 0.1181\n",
      "Epoch 31 Batch 100: Train Loss = 0.1486\n",
      "Epoch 31 Batch 120: Train Loss = 0.1994\n",
      "Epoch 31: Loss = 0.1267 Valid loss = 0.1307 roc = 0.9396\n",
      "confusion matrix:\n",
      "[[3888   30]\n",
      " [ 136  172]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9662027955055237\n",
      "precision class 1 = 0.8514851331710815\n",
      "recall class 0 = 0.992343008518219\n",
      "recall class 1 = 0.5584415793418884\n",
      "AUC of ROC = 0.9396044231419423\n",
      "AUC of PRC = 0.7481326293750783\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6745098428678541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 0: Train Loss = 0.1098\n",
      "Epoch 32 Batch 20: Train Loss = 0.1676\n",
      "Epoch 32 Batch 40: Train Loss = 0.1743\n",
      "Epoch 32 Batch 60: Train Loss = 0.1028\n",
      "Epoch 32 Batch 80: Train Loss = 0.1106\n",
      "Epoch 32 Batch 100: Train Loss = 0.1189\n",
      "Epoch 32 Batch 120: Train Loss = 0.1461\n",
      "Epoch 32: Loss = 0.1268 Valid loss = 0.1198 roc = 0.9462\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9690077304840088\n",
      "precision class 1 = 0.8177777528762817\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9461584229960952\n",
      "AUC of PRC = 0.7559583504137042\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6904314942817796\n",
      "------------ Save best model - AUROC: 0.9462 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 0: Train Loss = 0.1491\n",
      "Epoch 33 Batch 20: Train Loss = 0.0605\n",
      "Epoch 33 Batch 40: Train Loss = 0.1155\n",
      "Epoch 33 Batch 60: Train Loss = 0.1091\n",
      "Epoch 33 Batch 80: Train Loss = 0.1959\n",
      "Epoch 33 Batch 100: Train Loss = 0.1686\n",
      "Epoch 33 Batch 120: Train Loss = 0.1025\n",
      "Epoch 33: Loss = 0.1282 Valid loss = 0.1200 roc = 0.9454\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 112  196]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9718309640884399\n",
      "precision class 1 = 0.7839999794960022\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.6363636255264282\n",
      "AUC of ROC = 0.9454474188394556\n",
      "AUC of PRC = 0.7566563217201274\n",
      "min(+P, Se) = 0.6893203883495146\n",
      "f1_score = 0.7025089162580245\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 0: Train Loss = 0.1143\n",
      "Epoch 34 Batch 20: Train Loss = 0.1101\n",
      "Epoch 34 Batch 40: Train Loss = 0.0762\n",
      "Epoch 34 Batch 60: Train Loss = 0.1049\n",
      "Epoch 34 Batch 80: Train Loss = 0.1290\n",
      "Epoch 34 Batch 100: Train Loss = 0.1508\n",
      "Epoch 34 Batch 120: Train Loss = 0.0915\n",
      "Epoch 34: Loss = 0.1243 Valid loss = 0.1186 roc = 0.9462\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9708908200263977\n",
      "precision class 1 = 0.7966805100440979\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9461650524054812\n",
      "AUC of PRC = 0.765511530662764\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6994535761961407\n",
      "------------ Save best model - AUROC: 0.9462 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 0: Train Loss = 0.1115\n",
      "Epoch 35 Batch 20: Train Loss = 0.1751\n",
      "Epoch 35 Batch 40: Train Loss = 0.1158\n",
      "Epoch 35 Batch 60: Train Loss = 0.1329\n",
      "Epoch 35 Batch 80: Train Loss = 0.1685\n",
      "Epoch 35 Batch 100: Train Loss = 0.1444\n",
      "Epoch 35 Batch 120: Train Loss = 0.0780\n",
      "Epoch 35: Loss = 0.1234 Valid loss = 0.1207 roc = 0.9441\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9690077304840088\n",
      "precision class 1 = 0.8177777528762817\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9441182222575791\n",
      "AUC of PRC = 0.7552499606865726\n",
      "min(+P, Se) = 0.6967741935483871\n",
      "f1_score = 0.6904314942817796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 0: Train Loss = 0.1181\n",
      "Epoch 36 Batch 20: Train Loss = 0.1137\n",
      "Epoch 36 Batch 40: Train Loss = 0.1225\n",
      "Epoch 36 Batch 60: Train Loss = 0.1257\n",
      "Epoch 36 Batch 80: Train Loss = 0.0979\n",
      "Epoch 36 Batch 100: Train Loss = 0.1688\n",
      "Epoch 36 Batch 120: Train Loss = 0.1557\n",
      "Epoch 36: Loss = 0.1261 Valid loss = 0.1230 roc = 0.9434\n",
      "confusion matrix:\n",
      "[[3870   48]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.969924807548523\n",
      "precision class 1 = 0.7966101765632629\n",
      "recall class 0 = 0.9877488613128662\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9434088754532859\n",
      "AUC of PRC = 0.7568581045547778\n",
      "min(+P, Se) = 0.686084142394822\n",
      "f1_score = 0.6911764310666445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 0: Train Loss = 0.1094\n",
      "Epoch 37 Batch 20: Train Loss = 0.1030\n",
      "Epoch 37 Batch 40: Train Loss = 0.1193\n",
      "Epoch 37 Batch 60: Train Loss = 0.1307\n",
      "Epoch 37 Batch 80: Train Loss = 0.0964\n",
      "Epoch 37 Batch 100: Train Loss = 0.0883\n",
      "Epoch 37 Batch 120: Train Loss = 0.1074\n",
      "Epoch 37: Loss = 0.1251 Valid loss = 0.1222 roc = 0.9458\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 131  177]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9673072099685669\n",
      "precision class 1 = 0.8082191944122314\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.5746753215789795\n",
      "AUC of ROC = 0.9457507143188614\n",
      "AUC of PRC = 0.7556467304072083\n",
      "min(+P, Se) = 0.6876971608832808\n",
      "f1_score = 0.6717267587430432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 0: Train Loss = 0.1204\n",
      "Epoch 38 Batch 20: Train Loss = 0.1142\n",
      "Epoch 38 Batch 40: Train Loss = 0.1114\n",
      "Epoch 38 Batch 60: Train Loss = 0.1239\n",
      "Epoch 38 Batch 80: Train Loss = 0.1805\n",
      "Epoch 38 Batch 100: Train Loss = 0.0661\n",
      "Epoch 38 Batch 120: Train Loss = 0.1393\n",
      "Epoch 38: Loss = 0.1291 Valid loss = 0.1217 roc = 0.9439\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.970403790473938\n",
      "precision class 1 = 0.7949790954589844\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9438563605868353\n",
      "AUC of PRC = 0.7606190187569648\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6946983787945726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 0: Train Loss = 0.1380\n",
      "Epoch 39 Batch 20: Train Loss = 0.0972\n",
      "Epoch 39 Batch 40: Train Loss = 0.0852\n",
      "Epoch 39 Batch 60: Train Loss = 0.1036\n",
      "Epoch 39 Batch 80: Train Loss = 0.1367\n",
      "Epoch 39 Batch 100: Train Loss = 0.1511\n",
      "Epoch 39 Batch 120: Train Loss = 0.1657\n",
      "Epoch 39: Loss = 0.1229 Valid loss = 0.1257 roc = 0.9457\n",
      "confusion matrix:\n",
      "[[3837   81]\n",
      " [ 100  208]]\n",
      "accuracy = 0.9571698904037476\n",
      "precision class 0 = 0.9745999574661255\n",
      "precision class 1 = 0.7197231650352478\n",
      "recall class 0 = 0.9793261885643005\n",
      "recall class 1 = 0.6753246784210205\n",
      "AUC of ROC = 0.9457159099195852\n",
      "AUC of PRC = 0.7625597086945778\n",
      "min(+P, Se) = 0.6870967741935484\n",
      "f1_score = 0.6968173837086727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 0: Train Loss = 0.1133\n",
      "Epoch 40 Batch 20: Train Loss = 0.0953\n",
      "Epoch 40 Batch 40: Train Loss = 0.1241\n",
      "Epoch 40 Batch 60: Train Loss = 0.1218\n",
      "Epoch 40 Batch 80: Train Loss = 0.2038\n",
      "Epoch 40 Batch 100: Train Loss = 0.1453\n",
      "Epoch 40 Batch 120: Train Loss = 0.1919\n",
      "Epoch 40: Loss = 0.1260 Valid loss = 0.1195 roc = 0.9452\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 128  180]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9680079817771912\n",
      "precision class 1 = 0.800000011920929\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9451772704069795\n",
      "AUC of PRC = 0.7599428938110591\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6754220943608814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 0: Train Loss = 0.1282\n",
      "Epoch 41 Batch 20: Train Loss = 0.0617\n",
      "Epoch 41 Batch 40: Train Loss = 0.1358\n",
      "Epoch 41 Batch 60: Train Loss = 0.0690\n",
      "Epoch 41 Batch 80: Train Loss = 0.0837\n",
      "Epoch 41 Batch 100: Train Loss = 0.0834\n",
      "Epoch 41 Batch 120: Train Loss = 0.0806\n",
      "Epoch 41: Loss = 0.1236 Valid loss = 0.1217 roc = 0.9458\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 127  181]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9683212637901306\n",
      "precision class 1 = 0.8341013789176941\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9457532003473811\n",
      "AUC of PRC = 0.7567883241257003\n",
      "min(+P, Se) = 0.686084142394822\n",
      "f1_score = 0.6895238382763346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 0: Train Loss = 0.1472\n",
      "Epoch 42 Batch 20: Train Loss = 0.1672\n",
      "Epoch 42 Batch 40: Train Loss = 0.0820\n",
      "Epoch 42 Batch 60: Train Loss = 0.1629\n",
      "Epoch 42 Batch 80: Train Loss = 0.0868\n",
      "Epoch 42 Batch 100: Train Loss = 0.0761\n",
      "Epoch 42 Batch 120: Train Loss = 0.0834\n",
      "Epoch 42: Loss = 0.1233 Valid loss = 0.1208 roc = 0.9450\n",
      "confusion matrix:\n",
      "[[3893   25]\n",
      " [ 136  172]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9662446975708008\n",
      "precision class 1 = 0.8730964660644531\n",
      "recall class 0 = 0.9936192035675049\n",
      "recall class 1 = 0.5584415793418884\n",
      "AUC of ROC = 0.9449526991640315\n",
      "AUC of PRC = 0.7587654915606878\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.681188111891877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 0: Train Loss = 0.1077\n",
      "Epoch 43 Batch 20: Train Loss = 0.1175\n",
      "Epoch 43 Batch 40: Train Loss = 0.1716\n",
      "Epoch 43 Batch 60: Train Loss = 0.1321\n",
      "Epoch 43 Batch 80: Train Loss = 0.1137\n",
      "Epoch 43 Batch 100: Train Loss = 0.1646\n",
      "Epoch 43 Batch 120: Train Loss = 0.0986\n",
      "Epoch 43: Loss = 0.1206 Valid loss = 0.1275 roc = 0.9435\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 127  181]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9682420492172241\n",
      "precision class 1 = 0.7973568439483643\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9435389776124846\n",
      "AUC of PRC = 0.7520398123156387\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6766355207174852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 0: Train Loss = 0.1770\n",
      "Epoch 44 Batch 20: Train Loss = 0.1856\n",
      "Epoch 44 Batch 40: Train Loss = 0.0821\n",
      "Epoch 44 Batch 60: Train Loss = 0.0687\n",
      "Epoch 44 Batch 80: Train Loss = 0.1077\n",
      "Epoch 44 Batch 100: Train Loss = 0.1002\n",
      "Epoch 44 Batch 120: Train Loss = 0.0803\n",
      "Epoch 44: Loss = 0.1203 Valid loss = 0.1216 roc = 0.9469\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 135  173]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9664095640182495\n",
      "precision class 1 = 0.8357487916946411\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5616883039474487\n",
      "AUC of ROC = 0.9468594830386562\n",
      "AUC of PRC = 0.7599730478371791\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6718446544706905\n",
      "------------ Save best model - AUROC: 0.9469 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 0: Train Loss = 0.1491\n",
      "Epoch 45 Batch 20: Train Loss = 0.1125\n",
      "Epoch 45 Batch 40: Train Loss = 0.1345\n",
      "Epoch 45 Batch 60: Train Loss = 0.1315\n",
      "Epoch 45 Batch 80: Train Loss = 0.1260\n",
      "Epoch 45 Batch 100: Train Loss = 0.1008\n",
      "Epoch 45 Batch 120: Train Loss = 0.1351\n",
      "Epoch 45: Loss = 0.1227 Valid loss = 0.1276 roc = 0.9414\n",
      "confusion matrix:\n",
      "[[3857   61]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9571698904037476\n",
      "precision class 0 = 0.9698265194892883\n",
      "precision class 1 = 0.7550200819969177\n",
      "recall class 0 = 0.9844308495521545\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9413811048573684\n",
      "AUC of PRC = 0.739323234551599\n",
      "min(+P, Se) = 0.6893203883495146\n",
      "f1_score = 0.6750449011331833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 0: Train Loss = 0.1249\n",
      "Epoch 46 Batch 20: Train Loss = 0.1035\n",
      "Epoch 46 Batch 40: Train Loss = 0.1500\n",
      "Epoch 46 Batch 60: Train Loss = 0.1858\n",
      "Epoch 46 Batch 80: Train Loss = 0.1102\n",
      "Epoch 46 Batch 100: Train Loss = 0.1251\n",
      "Epoch 46 Batch 120: Train Loss = 0.1362\n",
      "Epoch 46: Loss = 0.1233 Valid loss = 0.1225 roc = 0.9456\n",
      "confusion matrix:\n",
      "[[3892   26]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9669564962387085\n",
      "precision class 1 = 0.8706467747688293\n",
      "recall class 0 = 0.9933639764785767\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9456189548073162\n",
      "AUC of PRC = 0.7665270078406281\n",
      "min(+P, Se) = 0.7142857142857143\n",
      "f1_score = 0.6876227884978444\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 0: Train Loss = 0.1144\n",
      "Epoch 47 Batch 20: Train Loss = 0.0813\n",
      "Epoch 47 Batch 40: Train Loss = 0.1033\n",
      "Epoch 47 Batch 60: Train Loss = 0.1110\n",
      "Epoch 47 Batch 80: Train Loss = 0.1253\n",
      "Epoch 47 Batch 100: Train Loss = 0.0774\n",
      "Epoch 47 Batch 120: Train Loss = 0.0983\n",
      "Epoch 47: Loss = 0.1205 Valid loss = 0.1213 roc = 0.9456\n",
      "confusion matrix:\n",
      "[[3851   67]\n",
      " [ 101  207]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.9744433164596558\n",
      "precision class 1 = 0.7554744482040405\n",
      "recall class 0 = 0.9828994274139404\n",
      "recall class 1 = 0.6720778942108154\n",
      "AUC of ROC = 0.94561481142645\n",
      "AUC of PRC = 0.763274832505558\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.7113401886478744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 0: Train Loss = 0.0812\n",
      "Epoch 48 Batch 20: Train Loss = 0.1222\n",
      "Epoch 48 Batch 40: Train Loss = 0.1066\n",
      "Epoch 48 Batch 60: Train Loss = 0.1674\n",
      "Epoch 48 Batch 80: Train Loss = 0.0773\n",
      "Epoch 48 Batch 100: Train Loss = 0.1314\n",
      "Epoch 48 Batch 120: Train Loss = 0.1320\n",
      "Epoch 48: Loss = 0.1171 Valid loss = 0.1244 roc = 0.9461\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 113  195]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9716222882270813\n",
      "precision class 1 = 0.7991803288459778\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.9460523524459206\n",
      "AUC of PRC = 0.7616953357437959\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.706521750598163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 0: Train Loss = 0.1051\n",
      "Epoch 49 Batch 20: Train Loss = 0.1384\n",
      "Epoch 49 Batch 40: Train Loss = 0.1503\n",
      "Epoch 49 Batch 60: Train Loss = 0.1238\n",
      "Epoch 49 Batch 80: Train Loss = 0.1295\n",
      "Epoch 49 Batch 100: Train Loss = 0.0951\n",
      "Epoch 49 Batch 120: Train Loss = 0.1290\n",
      "Epoch 49: Loss = 0.1199 Valid loss = 0.1226 roc = 0.9428\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 111  197]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9720754623413086\n",
      "precision class 1 = 0.7848605513572693\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.6396104097366333\n",
      "AUC of ROC = 0.9427649940666786\n",
      "AUC of PRC = 0.7598308642360331\n",
      "min(+P, Se) = 0.6925566343042071\n",
      "f1_score = 0.7048300927943225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 0: Train Loss = 0.1319\n",
      "Epoch 50 Batch 20: Train Loss = 0.1287\n",
      "Epoch 50 Batch 40: Train Loss = 0.0947\n",
      "Epoch 50 Batch 60: Train Loss = 0.0841\n",
      "Epoch 50 Batch 80: Train Loss = 0.1719\n",
      "Epoch 50 Batch 100: Train Loss = 0.0916\n",
      "Epoch 50 Batch 120: Train Loss = 0.1345\n",
      "Epoch 50: Loss = 0.1152 Valid loss = 0.1260 roc = 0.9459\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9668742418289185\n",
      "precision class 1 = 0.829383909702301\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.94593965248636\n",
      "AUC of PRC = 0.766443560016009\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6743737996950239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 0: Train Loss = 0.1306\n",
      "Epoch 51 Batch 20: Train Loss = 0.1337\n",
      "Epoch 51 Batch 40: Train Loss = 0.1456\n",
      "Epoch 51 Batch 60: Train Loss = 0.1441\n",
      "Epoch 51 Batch 80: Train Loss = 0.1052\n",
      "Epoch 51 Batch 100: Train Loss = 0.1281\n",
      "Epoch 51 Batch 120: Train Loss = 0.1427\n",
      "Epoch 51: Loss = 0.1159 Valid loss = 0.1219 roc = 0.9457\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9685471653938293\n",
      "precision class 1 = 0.8272727131843567\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9456736474347501\n",
      "AUC of PRC = 0.760377863953803\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6893939160638384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 0: Train Loss = 0.1130\n",
      "Epoch 52 Batch 20: Train Loss = 0.1577\n",
      "Epoch 52 Batch 40: Train Loss = 0.1043\n",
      "Epoch 52 Batch 60: Train Loss = 0.1276\n",
      "Epoch 52 Batch 80: Train Loss = 0.1556\n",
      "Epoch 52 Batch 100: Train Loss = 0.1250\n",
      "Epoch 52 Batch 120: Train Loss = 0.1581\n",
      "Epoch 52: Loss = 0.1150 Valid loss = 0.1191 roc = 0.9478\n",
      "confusion matrix:\n",
      "[[3847   71]\n",
      " [ 108  200]]\n",
      "accuracy = 0.9576431512832642\n",
      "precision class 0 = 0.9726927876472473\n",
      "precision class 1 = 0.7380073666572571\n",
      "recall class 0 = 0.9818785190582275\n",
      "recall class 1 = 0.649350643157959\n",
      "AUC of ROC = 0.9477726841815661\n",
      "AUC of PRC = 0.7723272169588365\n",
      "min(+P, Se) = 0.7161290322580646\n",
      "f1_score = 0.6908463069988034\n",
      "------------ Save best model - AUROC: 0.9478 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 0: Train Loss = 0.1605\n",
      "Epoch 53 Batch 20: Train Loss = 0.1192\n",
      "Epoch 53 Batch 40: Train Loss = 0.1425\n",
      "Epoch 53 Batch 60: Train Loss = 0.1150\n",
      "Epoch 53 Batch 80: Train Loss = 0.1275\n",
      "Epoch 53 Batch 100: Train Loss = 0.0797\n",
      "Epoch 53 Batch 120: Train Loss = 0.0867\n",
      "Epoch 53: Loss = 0.1149 Valid loss = 0.1246 roc = 0.9465\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 138  170]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9656887054443359\n",
      "precision class 1 = 0.8333333134651184\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.551948070526123\n",
      "AUC of ROC = 0.946454260389942\n",
      "AUC of PRC = 0.7655686444150662\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.664062535710401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 0: Train Loss = 0.1342\n",
      "Epoch 54 Batch 20: Train Loss = 0.0790\n",
      "Epoch 54 Batch 40: Train Loss = 0.1304\n",
      "Epoch 54 Batch 60: Train Loss = 0.0927\n",
      "Epoch 54 Batch 80: Train Loss = 0.1198\n",
      "Epoch 54 Batch 100: Train Loss = 0.1526\n",
      "Epoch 54 Batch 120: Train Loss = 0.1334\n",
      "Epoch 54: Loss = 0.1126 Valid loss = 0.1229 roc = 0.9468\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9684921503067017\n",
      "precision class 1 = 0.8017621040344238\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9468495389245772\n",
      "AUC of PRC = 0.7655023227988503\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.680373839154204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 0: Train Loss = 0.0520\n",
      "Epoch 55 Batch 20: Train Loss = 0.1103\n",
      "Epoch 55 Batch 40: Train Loss = 0.0804\n",
      "Epoch 55 Batch 60: Train Loss = 0.1032\n",
      "Epoch 55 Batch 80: Train Loss = 0.1087\n",
      "Epoch 55 Batch 100: Train Loss = 0.1749\n",
      "Epoch 55 Batch 120: Train Loss = 0.0865\n",
      "Epoch 55: Loss = 0.1138 Valid loss = 0.1216 roc = 0.9481\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9694617986679077\n",
      "precision class 1 = 0.8051947951316833\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9480610634898536\n",
      "AUC of PRC = 0.7673300186237254\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6901669575243579\n",
      "------------ Save best model - AUROC: 0.9481 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 0: Train Loss = 0.1153\n",
      "Epoch 56 Batch 20: Train Loss = 0.1111\n",
      "Epoch 56 Batch 40: Train Loss = 0.0880\n",
      "Epoch 56 Batch 60: Train Loss = 0.0804\n",
      "Epoch 56 Batch 80: Train Loss = 0.2231\n",
      "Epoch 56 Batch 100: Train Loss = 0.0925\n",
      "Epoch 56 Batch 120: Train Loss = 0.0989\n",
      "Epoch 56: Loss = 0.1119 Valid loss = 0.1195 roc = 0.9472\n",
      "confusion matrix:\n",
      "[[3885   33]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9685863852500916\n",
      "precision class 1 = 0.8465116024017334\n",
      "recall class 0 = 0.9915773272514343\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9472050410028972\n",
      "AUC of PRC = 0.7701760787637186\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6959847050798093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 0: Train Loss = 0.0892\n",
      "Epoch 57 Batch 20: Train Loss = 0.0961\n",
      "Epoch 57 Batch 40: Train Loss = 0.1010\n",
      "Epoch 57 Batch 60: Train Loss = 0.1353\n",
      "Epoch 57 Batch 80: Train Loss = 0.1608\n",
      "Epoch 57 Batch 100: Train Loss = 0.1175\n",
      "Epoch 57 Batch 120: Train Loss = 0.1254\n",
      "Epoch 57: Loss = 0.1159 Valid loss = 0.1219 roc = 0.9434\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.969188392162323\n",
      "precision class 1 = 0.7905982732772827\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9434445085287351\n",
      "AUC of PRC = 0.7633265791785279\n",
      "min(+P, Se) = 0.6753246753246753\n",
      "f1_score = 0.6826568241107436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 0: Train Loss = 0.1404\n",
      "Epoch 58 Batch 20: Train Loss = 0.1224\n",
      "Epoch 58 Batch 40: Train Loss = 0.1471\n",
      "Epoch 58 Batch 60: Train Loss = 0.1091\n",
      "Epoch 58 Batch 80: Train Loss = 0.0917\n",
      "Epoch 58 Batch 100: Train Loss = 0.0811\n",
      "Epoch 58 Batch 120: Train Loss = 0.1594\n",
      "Epoch 58: Loss = 0.1107 Valid loss = 0.1246 roc = 0.9451\n",
      "confusion matrix:\n",
      "[[3860   58]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9588263034820557\n",
      "precision class 0 = 0.9708249568939209\n",
      "precision class 1 = 0.7680000066757202\n",
      "recall class 0 = 0.9851965308189392\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9450703711806315\n",
      "AUC of PRC = 0.7495620278277833\n",
      "min(+P, Se) = 0.6785714285714286\n",
      "f1_score = 0.6881720362570756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 0: Train Loss = 0.1105\n",
      "Epoch 59 Batch 20: Train Loss = 0.1394\n",
      "Epoch 59 Batch 40: Train Loss = 0.1077\n",
      "Epoch 59 Batch 60: Train Loss = 0.0548\n",
      "Epoch 59 Batch 80: Train Loss = 0.1358\n",
      "Epoch 59 Batch 100: Train Loss = 0.0731\n",
      "Epoch 59 Batch 120: Train Loss = 0.1041\n",
      "Epoch 59: Loss = 0.1120 Valid loss = 0.1201 roc = 0.9466\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9708908200263977\n",
      "precision class 1 = 0.7966805100440979\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9466117088628575\n",
      "AUC of PRC = 0.7723730746208438\n",
      "min(+P, Se) = 0.6957928802588996\n",
      "f1_score = 0.6994535761961407\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 0: Train Loss = 0.0793\n",
      "Epoch 60 Batch 80: Train Loss = 0.1384\n",
      "Epoch 60 Batch 100: Train Loss = 0.0932\n",
      "Epoch 60 Batch 120: Train Loss = 0.0735\n",
      "Epoch 60: Loss = 0.1134 Valid loss = 0.1202 roc = 0.9494\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9706472754478455\n",
      "precision class 1 = 0.7958333492279053\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9494217497663134\n",
      "AUC of PRC = 0.7687644013388524\n",
      "min(+P, Se) = 0.6957928802588996\n",
      "f1_score = 0.6970803357255485\n",
      "------------ Save best model - AUROC: 0.9494 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 0: Train Loss = 0.1051\n",
      "Epoch 61 Batch 20: Train Loss = 0.1113\n",
      "Epoch 61 Batch 40: Train Loss = 0.1489\n",
      "Epoch 61 Batch 60: Train Loss = 0.1276\n",
      "Epoch 61 Batch 80: Train Loss = 0.1132\n",
      "Epoch 61 Batch 100: Train Loss = 0.0950\n",
      "Epoch 61 Batch 120: Train Loss = 0.1758\n",
      "Epoch 61: Loss = 0.1140 Valid loss = 0.1202 roc = 0.9483\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9704186320304871\n",
      "precision class 1 = 0.8016877770423889\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9483162957512117\n",
      "AUC of PRC = 0.7666686286203974\n",
      "min(+P, Se) = 0.7\n",
      "f1_score = 0.6972477000908117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 0: Train Loss = 0.0894\n",
      "Epoch 62 Batch 20: Train Loss = 0.1007\n",
      "Epoch 62 Batch 40: Train Loss = 0.1102\n",
      "Epoch 62 Batch 60: Train Loss = 0.1258\n",
      "Epoch 62 Batch 80: Train Loss = 0.0956\n",
      "Epoch 62 Batch 100: Train Loss = 0.1254\n",
      "Epoch 62 Batch 120: Train Loss = 0.1367\n",
      "Epoch 62: Loss = 0.1130 Valid loss = 0.1217 roc = 0.9502\n",
      "confusion matrix:\n",
      "[[3852   66]\n",
      " [ 103  205]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9739570021629333\n",
      "precision class 1 = 0.7564575672149658\n",
      "recall class 0 = 0.9831546545028687\n",
      "recall class 1 = 0.6655844449996948\n",
      "AUC of ROC = 0.9501866178742135\n",
      "AUC of PRC = 0.7655210608422154\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.7081174616725597\n",
      "------------ Save best model - AUROC: 0.9502 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 0: Train Loss = 0.1082\n",
      "Epoch 63 Batch 20: Train Loss = 0.1177\n",
      "Epoch 63 Batch 40: Train Loss = 0.1348\n",
      "Epoch 63 Batch 60: Train Loss = 0.0831\n",
      "Epoch 63 Batch 80: Train Loss = 0.0868\n",
      "Epoch 63 Batch 100: Train Loss = 0.1407\n",
      "Epoch 63 Batch 120: Train Loss = 0.0762\n",
      "Epoch 63: Loss = 0.1094 Valid loss = 0.1221 roc = 0.9491\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.967581033706665\n",
      "precision class 1 = 0.8240740895271301\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.9490571322500878\n",
      "AUC of PRC = 0.7615706121651253\n",
      "min(+P, Se) = 0.6913183279742765\n",
      "f1_score = 0.67938936636808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 0: Train Loss = 0.0961\n",
      "Epoch 64 Batch 20: Train Loss = 0.1171\n",
      "Epoch 64 Batch 40: Train Loss = 0.1276\n",
      "Epoch 64 Batch 60: Train Loss = 0.0991\n",
      "Epoch 64 Batch 80: Train Loss = 0.0902\n",
      "Epoch 64 Batch 100: Train Loss = 0.1294\n",
      "Epoch 64 Batch 120: Train Loss = 0.1059\n",
      "Epoch 64: Loss = 0.1065 Valid loss = 0.1265 roc = 0.9491\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9628490209579468\n",
      "precision class 0 = 0.9711851477622986\n",
      "precision class 1 = 0.8212766051292419\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9491076814966555\n",
      "AUC of PRC = 0.7692707549072152\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.7108655459081551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 0: Train Loss = 0.0642\n",
      "Epoch 65 Batch 20: Train Loss = 0.1027\n",
      "Epoch 65 Batch 40: Train Loss = 0.0839\n",
      "Epoch 65 Batch 60: Train Loss = 0.0833\n",
      "Epoch 65 Batch 80: Train Loss = 0.1620\n",
      "Epoch 65 Batch 100: Train Loss = 0.0763\n",
      "Epoch 65 Batch 120: Train Loss = 0.1186\n",
      "Epoch 65: Loss = 0.1076 Valid loss = 0.1192 roc = 0.9508\n",
      "confusion matrix:\n",
      "[[3860   58]\n",
      " [ 108  200]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9727822542190552\n",
      "precision class 1 = 0.7751938104629517\n",
      "recall class 0 = 0.9851965308189392\n",
      "recall class 1 = 0.649350643157959\n",
      "AUC of ROC = 0.9508288419084745\n",
      "AUC of PRC = 0.7677576624676502\n",
      "min(+P, Se) = 0.7106109324758842\n",
      "f1_score = 0.7067137822434574\n",
      "------------ Save best model - AUROC: 0.9508 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 0: Train Loss = 0.0956\n",
      "Epoch 66 Batch 20: Train Loss = 0.1005\n",
      "Epoch 66 Batch 40: Train Loss = 0.0712\n",
      "Epoch 66 Batch 60: Train Loss = 0.1185\n",
      "Epoch 66 Batch 80: Train Loss = 0.0746\n",
      "Epoch 66 Batch 100: Train Loss = 0.1213\n",
      "Epoch 66 Batch 120: Train Loss = 0.1142\n",
      "Epoch 66: Loss = 0.1133 Valid loss = 0.1193 roc = 0.9480\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9704630970954895\n",
      "precision class 1 = 0.822510838508606\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9480163149764989\n",
      "AUC of PRC = 0.763836232164855\n",
      "min(+P, Se) = 0.7032258064516129\n",
      "f1_score = 0.7050092414933818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 0: Train Loss = 0.1269\n",
      "Epoch 67 Batch 20: Train Loss = 0.1253\n",
      "Epoch 67 Batch 40: Train Loss = 0.0768\n",
      "Epoch 67 Batch 60: Train Loss = 0.0880\n",
      "Epoch 67 Batch 80: Train Loss = 0.1692\n",
      "Epoch 67 Batch 100: Train Loss = 0.1084\n",
      "Epoch 67 Batch 120: Train Loss = 0.0527\n",
      "Epoch 67: Loss = 0.1144 Valid loss = 0.1208 roc = 0.9458\n",
      "confusion matrix:\n",
      "[[3865   53]\n",
      " [ 112  196]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9718380570411682\n",
      "precision class 1 = 0.7871485948562622\n",
      "recall class 0 = 0.9864726662635803\n",
      "recall class 1 = 0.6363636255264282\n",
      "AUC of ROC = 0.9457780606325783\n",
      "AUC of PRC = 0.765679689512187\n",
      "min(+P, Se) = 0.7022653721682848\n",
      "f1_score = 0.7037701910505574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 0: Train Loss = 0.0903\n",
      "Epoch 68 Batch 20: Train Loss = 0.0784\n",
      "Epoch 68 Batch 40: Train Loss = 0.0940\n",
      "Epoch 68 Batch 60: Train Loss = 0.1071\n",
      "Epoch 68 Batch 80: Train Loss = 0.0881\n",
      "Epoch 68 Batch 100: Train Loss = 0.1167\n",
      "Epoch 68 Batch 120: Train Loss = 0.0723\n",
      "Epoch 68: Loss = 0.1104 Valid loss = 0.1262 roc = 0.9448\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9704630970954895\n",
      "precision class 1 = 0.822510838508606\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9447869639293834\n",
      "AUC of PRC = 0.7690155552229049\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.7050092414933818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 0: Train Loss = 0.0678\n",
      "Epoch 69 Batch 20: Train Loss = 0.1164\n",
      "Epoch 69 Batch 40: Train Loss = 0.1160\n",
      "Epoch 69 Batch 60: Train Loss = 0.1124\n",
      "Epoch 69 Batch 80: Train Loss = 0.0973\n",
      "Epoch 69 Batch 100: Train Loss = 0.1065\n",
      "Epoch 69 Batch 120: Train Loss = 0.1236\n",
      "Epoch 69: Loss = 0.1089 Valid loss = 0.1282 roc = 0.9462\n",
      "confusion matrix:\n",
      "[[3841   77]\n",
      " [  96  212]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9756159782409668\n",
      "precision class 1 = 0.733564019203186\n",
      "recall class 0 = 0.9803470969200134\n",
      "recall class 1 = 0.6883116960525513\n",
      "AUC of ROC = 0.9462495773751516\n",
      "AUC of PRC = 0.7682166228960117\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.7102177620778293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 0: Train Loss = 0.1067\n",
      "Epoch 70 Batch 20: Train Loss = 0.1512\n",
      "Epoch 70 Batch 40: Train Loss = 0.0868\n",
      "Epoch 70 Batch 60: Train Loss = 0.0960\n",
      "Epoch 70 Batch 80: Train Loss = 0.0974\n",
      "Epoch 70 Batch 100: Train Loss = 0.1367\n",
      "Epoch 70 Batch 120: Train Loss = 0.1087\n",
      "Epoch 70: Loss = 0.1113 Valid loss = 0.1185 roc = 0.9468\n",
      "confusion matrix:\n",
      "[[3870   48]\n",
      " [ 114  194]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9713855385780334\n",
      "precision class 1 = 0.8016529083251953\n",
      "recall class 0 = 0.9877488613128662\n",
      "recall class 1 = 0.6298701167106628\n",
      "AUC of ROC = 0.9468230212870336\n",
      "AUC of PRC = 0.7697688381921871\n",
      "min(+P, Se) = 0.707395498392283\n",
      "f1_score = 0.7054545139312755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 0: Train Loss = 0.0781\n",
      "Epoch 71 Batch 20: Train Loss = 0.1398\n",
      "Epoch 71 Batch 40: Train Loss = 0.1156\n",
      "Epoch 71 Batch 60: Train Loss = 0.1441\n",
      "Epoch 71 Batch 80: Train Loss = 0.1013\n",
      "Epoch 71 Batch 100: Train Loss = 0.1572\n",
      "Epoch 71 Batch 120: Train Loss = 0.1033\n",
      "Epoch 71: Loss = 0.1068 Valid loss = 0.1291 roc = 0.9464\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.969273030757904\n",
      "precision class 1 = 0.8295964002609253\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9464468023043827\n",
      "AUC of PRC = 0.7711813347038488\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6967984932387027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 0: Train Loss = 0.0943\n",
      "Epoch 72 Batch 20: Train Loss = 0.0858\n",
      "Epoch 72 Batch 40: Train Loss = 0.1406\n",
      "Epoch 72 Batch 60: Train Loss = 0.0974\n",
      "Epoch 72 Batch 80: Train Loss = 0.1124\n",
      "Epoch 72 Batch 100: Train Loss = 0.1098\n",
      "Epoch 72 Batch 120: Train Loss = 0.1286\n",
      "Epoch 72: Loss = 0.1082 Valid loss = 0.1244 roc = 0.9442\n",
      "confusion matrix:\n",
      "[[3861   57]\n",
      " [ 119  189]]\n",
      "accuracy = 0.9583530426025391\n",
      "precision class 0 = 0.9701005220413208\n",
      "precision class 1 = 0.7682926654815674\n",
      "recall class 0 = 0.9854517579078674\n",
      "recall class 1 = 0.6136363744735718\n",
      "AUC of ROC = 0.9441530266568552\n",
      "AUC of PRC = 0.7653066259257809\n",
      "min(+P, Se) = 0.6893203883495146\n",
      "f1_score = 0.6823104691338568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 0: Train Loss = 0.0607\n",
      "Epoch 73 Batch 20: Train Loss = 0.1125\n",
      "Epoch 73 Batch 40: Train Loss = 0.1070\n",
      "Epoch 73 Batch 60: Train Loss = 0.1132\n",
      "Epoch 73 Batch 80: Train Loss = 0.0852\n",
      "Epoch 73 Batch 100: Train Loss = 0.0700\n",
      "Epoch 73 Batch 120: Train Loss = 0.0827\n",
      "Epoch 73: Loss = 0.1176 Valid loss = 0.1163 roc = 0.9477\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9709346294403076\n",
      "precision class 1 = 0.8170212507247925\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9477378797822902\n",
      "AUC of PRC = 0.7724215086503856\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.7071823007886627\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 0: Train Loss = 0.1320\n",
      "Epoch 74 Batch 20: Train Loss = 0.1333\n",
      "Epoch 74 Batch 40: Train Loss = 0.0584\n",
      "Epoch 74 Batch 60: Train Loss = 0.1105\n",
      "Epoch 74 Batch 80: Train Loss = 0.1114\n",
      "Epoch 74 Batch 100: Train Loss = 0.1276\n",
      "Epoch 74 Batch 120: Train Loss = 0.0886\n",
      "Epoch 74: Loss = 0.1110 Valid loss = 0.1191 roc = 0.9460\n",
      "confusion matrix:\n",
      "[[3867   51]\n",
      " [ 109  199]]\n",
      "accuracy = 0.9621391296386719\n",
      "precision class 0 = 0.9725854992866516\n",
      "precision class 1 = 0.7960000038146973\n",
      "recall class 0 = 0.9869831800460815\n",
      "recall class 1 = 0.6461039185523987\n",
      "AUC of ROC = 0.9459611980668643\n",
      "AUC of PRC = 0.7691474448763096\n",
      "min(+P, Se) = 0.7\n",
      "f1_score = 0.7132616934361786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 0: Train Loss = 0.0999\n",
      "Epoch 75 Batch 20: Train Loss = 0.1579\n",
      "Epoch 75 Batch 40: Train Loss = 0.1288\n",
      "Epoch 75 Batch 60: Train Loss = 0.1016\n",
      "Epoch 75 Batch 80: Train Loss = 0.1120\n",
      "Epoch 75 Batch 100: Train Loss = 0.0700\n",
      "Epoch 75 Batch 120: Train Loss = 0.1425\n",
      "Epoch 75: Loss = 0.1095 Valid loss = 0.1198 roc = 0.9478\n",
      "confusion matrix:\n",
      "[[3851   67]\n",
      " [ 105  203]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9734580516815186\n",
      "precision class 1 = 0.7518518567085266\n",
      "recall class 0 = 0.9828994274139404\n",
      "recall class 1 = 0.6590909361839294\n",
      "AUC of ROC = 0.9477967157905902\n",
      "AUC of PRC = 0.7746124916655281\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.7024221628345196\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 0: Train Loss = 0.1158\n",
      "Epoch 76 Batch 20: Train Loss = 0.1028\n",
      "Epoch 76 Batch 40: Train Loss = 0.0692\n",
      "Epoch 76 Batch 60: Train Loss = 0.1055\n",
      "Epoch 76 Batch 80: Train Loss = 0.0979\n",
      "Epoch 76 Batch 100: Train Loss = 0.1533\n",
      "Epoch 76 Batch 120: Train Loss = 0.1223\n",
      "Epoch 76: Loss = 0.1100 Valid loss = 0.1246 roc = 0.9453\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9692346453666687\n",
      "precision class 1 = 0.8114035129547119\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9453164880040839\n",
      "AUC of PRC = 0.759337721877251\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6902985130659747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 0: Train Loss = 0.1021\n",
      "Epoch 77 Batch 20: Train Loss = 0.1238\n",
      "Epoch 77 Batch 40: Train Loss = 0.1403\n",
      "Epoch 77 Batch 60: Train Loss = 0.1106\n",
      "Epoch 77 Batch 80: Train Loss = 0.1151\n",
      "Epoch 77 Batch 100: Train Loss = 0.0810\n",
      "Epoch 77 Batch 120: Train Loss = 0.1043\n",
      "Epoch 77: Loss = 0.1120 Valid loss = 0.1226 roc = 0.9446\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.9678143858909607\n",
      "precision class 1 = 0.8211008906364441\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9446220573709088\n",
      "AUC of PRC = 0.7655848188534794\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6806083552832441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 0: Train Loss = 0.0870\n",
      "Epoch 78 Batch 20: Train Loss = 0.0840\n",
      "Epoch 78 Batch 40: Train Loss = 0.1000\n",
      "Epoch 78 Batch 60: Train Loss = 0.0970\n",
      "Epoch 78 Batch 80: Train Loss = 0.1173\n",
      "Epoch 78 Batch 100: Train Loss = 0.0828\n",
      "Epoch 78 Batch 120: Train Loss = 0.1335\n",
      "Epoch 78: Loss = 0.1085 Valid loss = 0.1231 roc = 0.9441\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9710982441902161\n",
      "precision class 1 = 0.7813765406608582\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9440560715445862\n",
      "AUC of PRC = 0.7692792912608618\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6954954844792077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 0: Train Loss = 0.0837\n",
      "Epoch 79 Batch 20: Train Loss = 0.1071\n",
      "Epoch 79 Batch 40: Train Loss = 0.0896\n",
      "Epoch 79 Batch 60: Train Loss = 0.1100\n",
      "Epoch 79 Batch 80: Train Loss = 0.1236\n",
      "Epoch 79 Batch 100: Train Loss = 0.1010\n",
      "Epoch 79 Batch 120: Train Loss = 0.1251\n",
      "Epoch 79: Loss = 0.1088 Valid loss = 0.1205 roc = 0.9438\n",
      "confusion matrix:\n",
      "[[3862   56]\n",
      " [ 117  191]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9705955982208252\n",
      "precision class 1 = 0.7732793688774109\n",
      "recall class 0 = 0.9857069849967957\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9437809510550705\n",
      "AUC of PRC = 0.7673726882350764\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.688288302989703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 0: Train Loss = 0.0823\n",
      "Epoch 80 Batch 20: Train Loss = 0.1088\n",
      "Epoch 80 Batch 40: Train Loss = 0.1154\n",
      "Epoch 80 Batch 60: Train Loss = 0.1153\n",
      "Epoch 80 Batch 80: Train Loss = 0.1291\n",
      "Epoch 80 Batch 100: Train Loss = 0.1780\n",
      "Epoch 80 Batch 120: Train Loss = 0.0980\n",
      "Epoch 80: Loss = 0.1051 Valid loss = 0.1253 roc = 0.9444\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9626123905181885\n",
      "precision class 0 = 0.969530463218689\n",
      "precision class 1 = 0.837837815284729\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9443535662907792\n",
      "AUC of PRC = 0.7638374637194283\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.7018867983941985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 0: Train Loss = 0.1111\n",
      "Epoch 81 Batch 20: Train Loss = 0.0636\n",
      "Epoch 81 Batch 40: Train Loss = 0.0955\n",
      "Epoch 81 Batch 60: Train Loss = 0.0769\n",
      "Epoch 81 Batch 80: Train Loss = 0.0854\n",
      "Epoch 81 Batch 100: Train Loss = 0.1431\n",
      "Epoch 81 Batch 120: Train Loss = 0.0674\n",
      "Epoch 81: Loss = 0.1065 Valid loss = 0.1287 roc = 0.9436\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9709200263023376\n",
      "precision class 1 = 0.8101266026496887\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9435580371644691\n",
      "AUC of PRC = 0.7685238405121954\n",
      "min(+P, Se) = 0.6927899686520376\n",
      "f1_score = 0.7045871830753145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 0: Train Loss = 0.0785\n",
      "Epoch 82 Batch 20: Train Loss = 0.1167\n",
      "Epoch 82 Batch 40: Train Loss = 0.0856\n",
      "Epoch 82 Batch 60: Train Loss = 0.1661\n",
      "Epoch 82 Batch 80: Train Loss = 0.0587\n",
      "Epoch 82 Batch 100: Train Loss = 0.1072\n",
      "Epoch 82 Batch 120: Train Loss = 0.1422\n",
      "Epoch 82: Loss = 0.1073 Valid loss = 0.1276 roc = 0.9442\n",
      "confusion matrix:\n",
      "[[3867   51]\n",
      " [ 114  194]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9713639616966248\n",
      "precision class 1 = 0.7918367385864258\n",
      "recall class 0 = 0.9869831800460815\n",
      "recall class 1 = 0.6298701167106628\n",
      "AUC of ROC = 0.9441513693045087\n",
      "AUC of PRC = 0.7651309328576362\n",
      "min(+P, Se) = 0.7022653721682848\n",
      "f1_score = 0.7016274503858566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 0: Train Loss = 0.1043\n",
      "Epoch 83 Batch 20: Train Loss = 0.0941\n",
      "Epoch 83 Batch 40: Train Loss = 0.0806\n",
      "Epoch 83 Batch 60: Train Loss = 0.1380\n",
      "Epoch 83 Batch 80: Train Loss = 0.0919\n",
      "Epoch 83 Batch 100: Train Loss = 0.0840\n",
      "Epoch 83 Batch 120: Train Loss = 0.0670\n",
      "Epoch 83: Loss = 0.1086 Valid loss = 0.1298 roc = 0.9432\n",
      "confusion matrix:\n",
      "[[3866   52]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9706251621246338\n",
      "precision class 1 = 0.7860082387924194\n",
      "recall class 0 = 0.9867278933525085\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9432406541901183\n",
      "AUC of PRC = 0.7585172282501239\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6932849185593157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 0: Train Loss = 0.0841\n",
      "Epoch 84 Batch 20: Train Loss = 0.0863\n",
      "Epoch 84 Batch 40: Train Loss = 0.1064\n",
      "Epoch 84 Batch 60: Train Loss = 0.1204\n",
      "Epoch 84 Batch 80: Train Loss = 0.1346\n",
      "Epoch 84 Batch 100: Train Loss = 0.1305\n",
      "Epoch 84 Batch 120: Train Loss = 0.1252\n",
      "Epoch 84: Loss = 0.1091 Valid loss = 0.1217 roc = 0.9458\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.970661997795105\n",
      "precision class 1 = 0.8025209903717041\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9458277812029726\n",
      "AUC of PRC = 0.7711411501285466\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6996337304689015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 0: Train Loss = 0.0900\n",
      "Epoch 85 Batch 20: Train Loss = 0.0879\n",
      "Epoch 85 Batch 40: Train Loss = 0.0840\n",
      "Epoch 85 Batch 60: Train Loss = 0.0575\n",
      "Epoch 85 Batch 80: Train Loss = 0.0941\n",
      "Epoch 85 Batch 100: Train Loss = 0.0663\n",
      "Epoch 85 Batch 120: Train Loss = 0.1551\n",
      "Epoch 85: Loss = 0.1091 Valid loss = 0.1279 roc = 0.9420\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 138  170]]\n",
      "accuracy = 0.9588263034820557\n",
      "precision class 0 = 0.9656716585159302\n",
      "precision class 1 = 0.8252426981925964\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.551948070526123\n",
      "AUC of ROC = 0.9419686362641951\n",
      "AUC of PRC = 0.7515197196170735\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.661478577428089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 0: Train Loss = 0.1002\n",
      "Epoch 86 Batch 20: Train Loss = 0.1018\n",
      "Epoch 86 Batch 40: Train Loss = 0.1106\n",
      "Epoch 86 Batch 60: Train Loss = 0.1095\n",
      "Epoch 86 Batch 80: Train Loss = 0.0504\n",
      "Epoch 86 Batch 100: Train Loss = 0.0770\n",
      "Epoch 86 Batch 120: Train Loss = 0.1320\n",
      "Epoch 86: Loss = 0.1186 Valid loss = 0.1282 roc = 0.9464\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 132  176]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.9671151041984558\n",
      "precision class 1 = 0.8301886916160583\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5714285969734192\n",
      "AUC of ROC = 0.9463730501249643\n",
      "AUC of PRC = 0.7563611590080315\n",
      "min(+P, Se) = 0.6957928802588996\n",
      "f1_score = 0.6769230989591608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 0: Train Loss = 0.1514\n",
      "Epoch 87 Batch 20: Train Loss = 0.0953\n",
      "Epoch 87 Batch 40: Train Loss = 0.1125\n",
      "Epoch 87 Batch 60: Train Loss = 0.0958\n",
      "Epoch 87 Batch 80: Train Loss = 0.0737\n",
      "Epoch 87 Batch 100: Train Loss = 0.1358\n",
      "Epoch 87 Batch 120: Train Loss = 0.0868\n",
      "Epoch 87: Loss = 0.1151 Valid loss = 0.1254 roc = 0.9441\n",
      "confusion matrix:\n",
      "[[3865   53]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9703741073608398\n",
      "precision class 1 = 0.7818930149078369\n",
      "recall class 0 = 0.9864726662635803\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9440991627055946\n",
      "AUC of PRC = 0.7524504016537185\n",
      "min(+P, Se) = 0.7142857142857143\n",
      "f1_score = 0.6896551948734412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 0: Train Loss = 0.1334\n",
      "Epoch 88 Batch 20: Train Loss = 0.1155\n",
      "Epoch 88 Batch 40: Train Loss = 0.0791\n",
      "Epoch 88 Batch 60: Train Loss = 0.0756\n",
      "Epoch 88 Batch 80: Train Loss = 0.0653\n",
      "Epoch 88 Batch 100: Train Loss = 0.1086\n",
      "Epoch 88 Batch 120: Train Loss = 0.1422\n",
      "Epoch 88: Loss = 0.1147 Valid loss = 0.1250 roc = 0.9404\n",
      "confusion matrix:\n",
      "[[3868   50]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.969666600227356\n",
      "precision class 1 = 0.7890295386314392\n",
      "recall class 0 = 0.9872384071350098\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9403941515350397\n",
      "AUC of PRC = 0.7527410546692238\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6862385385954142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 0: Train Loss = 0.1360\n",
      "Epoch 89 Batch 20: Train Loss = 0.1137\n",
      "Epoch 89 Batch 40: Train Loss = 0.0841\n",
      "Epoch 89 Batch 60: Train Loss = 0.1116\n",
      "Epoch 89 Batch 80: Train Loss = 0.0925\n",
      "Epoch 89 Batch 100: Train Loss = 0.1494\n",
      "Epoch 89 Batch 120: Train Loss = 0.1009\n",
      "Epoch 89: Loss = 0.1130 Valid loss = 0.1287 roc = 0.9388\n",
      "confusion matrix:\n",
      "[[3866   52]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9706251621246338\n",
      "precision class 1 = 0.7860082387924194\n",
      "recall class 0 = 0.9867278933525085\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9388122087203251\n",
      "AUC of PRC = 0.7547385363192237\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6932849185593157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 0: Train Loss = 0.0779\n",
      "Epoch 90 Batch 20: Train Loss = 0.1202\n",
      "Epoch 90 Batch 40: Train Loss = 0.0756\n",
      "Epoch 90 Batch 60: Train Loss = 0.0915\n",
      "Epoch 90 Batch 80: Train Loss = 0.0802\n",
      "Epoch 90 Batch 100: Train Loss = 0.0955\n",
      "Epoch 90 Batch 120: Train Loss = 0.1665\n",
      "Epoch 90: Loss = 0.1113 Valid loss = 0.1340 roc = 0.9368\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9585896730422974\n",
      "precision class 0 = 0.967758059501648\n",
      "precision class 1 = 0.7955555319786072\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9367695219532892\n",
      "AUC of PRC = 0.7422434083434049\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6716697847011609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 0: Train Loss = 0.0993\n",
      "Epoch 91 Batch 20: Train Loss = 0.1420\n",
      "Epoch 91 Batch 40: Train Loss = 0.0856\n",
      "Epoch 91 Batch 60: Train Loss = 0.0701\n",
      "Epoch 91 Batch 80: Train Loss = 0.1424\n",
      "Epoch 91 Batch 100: Train Loss = 0.0899\n",
      "Epoch 91 Batch 120: Train Loss = 0.1695\n",
      "Epoch 91: Loss = 0.1158 Valid loss = 0.1253 roc = 0.9394\n",
      "confusion matrix:\n",
      "[[3861   57]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.969613254070282\n",
      "precision class 1 = 0.7663934230804443\n",
      "recall class 0 = 0.9854517579078674\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9393516769091041\n",
      "AUC of PRC = 0.755853181939561\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6775362001474963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 0: Train Loss = 0.0710\n",
      "Epoch 92 Batch 20: Train Loss = 0.0660\n",
      "Epoch 92 Batch 40: Train Loss = 0.0929\n",
      "Epoch 92 Batch 60: Train Loss = 0.1202\n",
      "Epoch 92 Batch 80: Train Loss = 0.1193\n",
      "Epoch 92 Batch 100: Train Loss = 0.0803\n",
      "Epoch 92 Batch 120: Train Loss = 0.0922\n",
      "Epoch 92: Loss = 0.1078 Valid loss = 0.1293 roc = 0.9426\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9697121381759644\n",
      "precision class 1 = 0.8095238208770752\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9426000875082039\n",
      "AUC of PRC = 0.7600766035145123\n",
      "min(+P, Se) = 0.7175324675324676\n",
      "f1_score = 0.6938775315576683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 0: Train Loss = 0.0813\n",
      "Epoch 93 Batch 20: Train Loss = 0.0910\n",
      "Epoch 93 Batch 40: Train Loss = 0.0841\n",
      "Epoch 93 Batch 60: Train Loss = 0.1142\n",
      "Epoch 93 Batch 80: Train Loss = 0.1142\n",
      "Epoch 93 Batch 100: Train Loss = 0.1251\n",
      "Epoch 93 Batch 120: Train Loss = 0.0981\n",
      "Epoch 93: Loss = 0.1138 Valid loss = 0.1225 roc = 0.9420\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 139  169]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9654486775398254\n",
      "precision class 1 = 0.8325123190879822\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.548701286315918\n",
      "AUC of ROC = 0.941964492883329\n",
      "AUC of PRC = 0.75517038103595\n",
      "min(+P, Se) = 0.6828478964401294\n",
      "f1_score = 0.6614481045618641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 0: Train Loss = 0.1135\n",
      "Epoch 94 Batch 20: Train Loss = 0.1320\n",
      "Epoch 94 Batch 40: Train Loss = 0.0779\n",
      "Epoch 94 Batch 60: Train Loss = 0.1000\n",
      "Epoch 94 Batch 80: Train Loss = 0.1479\n",
      "Epoch 94 Batch 100: Train Loss = 0.0803\n",
      "Epoch 94 Batch 120: Train Loss = 0.0939\n",
      "Epoch 94: Loss = 0.1081 Valid loss = 0.1259 roc = 0.9394\n",
      "confusion matrix:\n",
      "[[3865   53]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.9711055159568787\n",
      "precision class 1 = 0.7845528721809387\n",
      "recall class 0 = 0.9864726662635803\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9393566489661437\n",
      "AUC of PRC = 0.7552476708759535\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.696750952036942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 0: Train Loss = 0.0664\n",
      "Epoch 95 Batch 20: Train Loss = 0.0759\n",
      "Epoch 95 Batch 40: Train Loss = 0.1126\n",
      "Epoch 95 Batch 60: Train Loss = 0.0688\n",
      "Epoch 95 Batch 80: Train Loss = 0.0674\n",
      "Epoch 95 Batch 100: Train Loss = 0.0877\n",
      "Epoch 95 Batch 120: Train Loss = 0.1703\n",
      "Epoch 95: Loss = 0.1075 Valid loss = 0.1226 roc = 0.9419\n",
      "confusion matrix:\n",
      "[[3878   40]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9690154790878296\n",
      "precision class 1 = 0.8214285969734192\n",
      "recall class 0 = 0.9897907376289368\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.941905656875029\n",
      "AUC of PRC = 0.7630517149751485\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6917293448197214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 0: Train Loss = 0.0938\n",
      "Epoch 96 Batch 20: Train Loss = 0.0562\n",
      "Epoch 96 Batch 40: Train Loss = 0.0953\n",
      "Epoch 96 Batch 60: Train Loss = 0.1045\n",
      "Epoch 96 Batch 80: Train Loss = 0.1176\n",
      "Epoch 96 Batch 100: Train Loss = 0.0993\n",
      "Epoch 96 Batch 120: Train Loss = 0.1026\n",
      "Epoch 96: Loss = 0.1042 Valid loss = 0.1246 roc = 0.9405\n",
      "confusion matrix:\n",
      "[[3867   51]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9703889489173889\n",
      "precision class 1 = 0.7883817553520203\n",
      "recall class 0 = 0.9869831800460815\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9405341978083173\n",
      "AUC of PRC = 0.7599908820528735\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6921675710674047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 0: Train Loss = 0.0989\n",
      "Epoch 97 Batch 20: Train Loss = 0.1114\n",
      "Epoch 97 Batch 40: Train Loss = 0.1078\n",
      "Epoch 97 Batch 60: Train Loss = 0.0761\n",
      "Epoch 97 Batch 80: Train Loss = 0.1232\n",
      "Epoch 97 Batch 100: Train Loss = 0.1180\n",
      "Epoch 97 Batch 120: Train Loss = 0.1128\n",
      "Epoch 97: Loss = 0.1048 Valid loss = 0.1238 roc = 0.9426\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 121  187]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9697272777557373\n",
      "precision class 1 = 0.8165938854217529\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9426365492598264\n",
      "AUC of PRC = 0.7662204410490385\n",
      "min(+P, Se) = 0.6952380952380952\n",
      "f1_score = 0.6964618010197327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 0: Train Loss = 0.0610\n",
      "Epoch 98 Batch 20: Train Loss = 0.0694\n",
      "Epoch 98 Batch 40: Train Loss = 0.1291\n",
      "Epoch 98 Batch 60: Train Loss = 0.1635\n",
      "Epoch 98 Batch 80: Train Loss = 0.1624\n",
      "Epoch 98 Batch 100: Train Loss = 0.1393\n",
      "Epoch 98 Batch 120: Train Loss = 0.0678\n",
      "Epoch 98: Loss = 0.1030 Valid loss = 0.1236 roc = 0.9426\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9692268967628479\n",
      "precision class 1 = 0.807860255241394\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9426257764695742\n",
      "AUC of PRC = 0.7611048581688126\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.689013036994804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 0: Train Loss = 0.0637\n",
      "Epoch 99 Batch 20: Train Loss = 0.0925\n",
      "Epoch 99 Batch 40: Train Loss = 0.0681\n",
      "Epoch 99 Batch 60: Train Loss = 0.0856\n",
      "Epoch 99 Batch 80: Train Loss = 0.0883\n",
      "Epoch 99 Batch 100: Train Loss = 0.1138\n",
      "Epoch 99 Batch 120: Train Loss = 0.1245\n",
      "Epoch 99: Loss = 0.1039 Valid loss = 0.1225 roc = 0.9440\n",
      "confusion matrix:\n",
      "[[3878   40]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9697424173355103\n",
      "precision class 1 = 0.8237885236740112\n",
      "recall class 0 = 0.9897907376289368\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9439524870229311\n",
      "AUC of PRC = 0.7657441080391196\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6990654471934931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Batch 0: Train Loss = 0.1467\n",
      "Epoch 100 Batch 20: Train Loss = 0.1254\n",
      "Epoch 100 Batch 40: Train Loss = 0.1203\n",
      "Epoch 100 Batch 60: Train Loss = 0.1959\n",
      "Epoch 100 Batch 80: Train Loss = 0.0736\n",
      "Epoch 100 Batch 100: Train Loss = 0.0966\n",
      "Epoch 100 Batch 120: Train Loss = 0.0874\n",
      "Epoch 100: Loss = 0.1055 Valid loss = 0.1217 roc = 0.9438\n",
      "confusion matrix:\n",
      "[[3881   37]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9633222818374634\n",
      "precision class 0 = 0.9704926013946533\n",
      "precision class 1 = 0.8370044231414795\n",
      "recall class 0 = 0.9905564188957214\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9437536047413535\n",
      "AUC of PRC = 0.7711630118288112\n",
      "min(+P, Se) = 0.7087378640776699\n",
      "f1_score = 0.7102803975782583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 Batch 0: Train Loss = 0.0932\n",
      "Epoch 101 Batch 20: Train Loss = 0.0729\n",
      "Epoch 101 Batch 40: Train Loss = 0.1129\n",
      "Epoch 101 Batch 60: Train Loss = 0.0875\n",
      "Epoch 101 Batch 80: Train Loss = 0.1555\n",
      "Epoch 101 Batch 100: Train Loss = 0.0799\n",
      "Epoch 101 Batch 120: Train Loss = 0.1069\n",
      "Epoch 101: Loss = 0.1022 Valid loss = 0.1250 roc = 0.9460\n",
      "confusion matrix:\n",
      "[[3857   61]\n",
      " [ 109  199]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9725164175033569\n",
      "precision class 1 = 0.7653846144676208\n",
      "recall class 0 = 0.9844308495521545\n",
      "recall class 1 = 0.6461039185523987\n",
      "AUC of ROC = 0.946046551712708\n",
      "AUC of PRC = 0.7605139857558453\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.7007042381692985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 Batch 0: Train Loss = 0.0789\n",
      "Epoch 102 Batch 20: Train Loss = 0.0728\n",
      "Epoch 102 Batch 40: Train Loss = 0.1464\n",
      "Epoch 102 Batch 60: Train Loss = 0.0888\n",
      "Epoch 102 Batch 80: Train Loss = 0.1601\n",
      "Epoch 102 Batch 100: Train Loss = 0.0731\n",
      "Epoch 102 Batch 120: Train Loss = 0.1225\n",
      "Epoch 102: Loss = 0.1028 Valid loss = 0.1161 roc = 0.9484\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9621391296386719\n",
      "precision class 0 = 0.9704557061195374\n",
      "precision class 1 = 0.818965494632721\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9483850758735903\n",
      "AUC of PRC = 0.7741042493928614\n",
      "min(+P, Se) = 0.7175324675324676\n",
      "f1_score = 0.7037036837733495\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 Batch 0: Train Loss = 0.0848\n",
      "Epoch 103 Batch 20: Train Loss = 0.1326\n",
      "Epoch 103 Batch 40: Train Loss = 0.0981\n",
      "Epoch 103 Batch 60: Train Loss = 0.1133\n",
      "Epoch 103 Batch 80: Train Loss = 0.0828\n",
      "Epoch 103 Batch 100: Train Loss = 0.0618\n",
      "Epoch 103 Batch 120: Train Loss = 0.0765\n",
      "Epoch 103: Loss = 0.1001 Valid loss = 0.1271 roc = 0.9425\n",
      "confusion matrix:\n",
      "[[3861   57]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9581164121627808\n",
      "precision class 0 = 0.9698567986488342\n",
      "precision class 1 = 0.7673469185829163\n",
      "recall class 0 = 0.9854517579078674\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9424525831493671\n",
      "AUC of PRC = 0.7478025780955614\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6799276174404106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 Batch 0: Train Loss = 0.1581\n",
      "Epoch 104 Batch 20: Train Loss = 0.1110\n",
      "Epoch 104 Batch 40: Train Loss = 0.1135\n",
      "Epoch 104 Batch 60: Train Loss = 0.1138\n",
      "Epoch 104 Batch 80: Train Loss = 0.1012\n",
      "Epoch 104 Batch 100: Train Loss = 0.0804\n",
      "Epoch 104 Batch 120: Train Loss = 0.1115\n",
      "Epoch 104: Loss = 0.1053 Valid loss = 0.1255 roc = 0.9422\n",
      "confusion matrix:\n",
      "[[3870   48]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9708981513977051\n",
      "precision class 1 = 0.800000011920929\n",
      "recall class 0 = 0.9877488613128662\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9421600604602136\n",
      "AUC of PRC = 0.7582259402051775\n",
      "min(+P, Se) = 0.7175324675324676\n",
      "f1_score = 0.7007299511425923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Batch 0: Train Loss = 0.1335\n",
      "Epoch 105 Batch 20: Train Loss = 0.0682\n",
      "Epoch 105 Batch 40: Train Loss = 0.0648\n",
      "Epoch 105 Batch 60: Train Loss = 0.1047\n",
      "Epoch 105 Batch 80: Train Loss = 0.0820\n",
      "Epoch 105 Batch 100: Train Loss = 0.1035\n",
      "Epoch 105 Batch 120: Train Loss = 0.0536\n",
      "Epoch 105: Loss = 0.1023 Valid loss = 0.1251 roc = 0.9468\n",
      "confusion matrix:\n",
      "[[3881   37]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.969038724899292\n",
      "precision class 1 = 0.8325791954994202\n",
      "recall class 0 = 0.9905564188957214\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9468296506964194\n",
      "AUC of PRC = 0.7658790945794424\n",
      "min(+P, Se) = 0.7087378640776699\n",
      "f1_score = 0.6956521895983984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 Batch 0: Train Loss = 0.0934\n",
      "Epoch 106 Batch 20: Train Loss = 0.0903\n",
      "Epoch 106 Batch 40: Train Loss = 0.1513\n",
      "Epoch 106 Batch 60: Train Loss = 0.1220\n",
      "Epoch 106 Batch 80: Train Loss = 0.1152\n",
      "Epoch 106 Batch 100: Train Loss = 0.0956\n",
      "Epoch 106 Batch 120: Train Loss = 0.1089\n",
      "Epoch 106: Loss = 0.1009 Valid loss = 0.1234 roc = 0.9439\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 113  195]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9716222882270813\n",
      "precision class 1 = 0.7991803288459778\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.9439425429088523\n",
      "AUC of PRC = 0.7654111765168395\n",
      "min(+P, Se) = 0.7207792207792207\n",
      "f1_score = 0.706521750598163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 Batch 0: Train Loss = 0.1196\n",
      "Epoch 107 Batch 20: Train Loss = 0.1312\n",
      "Epoch 107 Batch 40: Train Loss = 0.1483\n",
      "Epoch 107 Batch 60: Train Loss = 0.1669\n",
      "Epoch 107 Batch 80: Train Loss = 0.0816\n",
      "Epoch 107 Batch 100: Train Loss = 0.0692\n",
      "Epoch 107 Batch 120: Train Loss = 0.0890\n",
      "Epoch 107: Loss = 0.1031 Valid loss = 0.1209 roc = 0.9455\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9706840515136719\n",
      "precision class 1 = 0.8127659559249878\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9454714504484796\n",
      "AUC of PRC = 0.7645967831257711\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.7034990578237206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 Batch 0: Train Loss = 0.0630\n",
      "Epoch 108 Batch 20: Train Loss = 0.0990\n",
      "Epoch 108 Batch 40: Train Loss = 0.1079\n",
      "Epoch 108 Batch 60: Train Loss = 0.0972\n",
      "Epoch 108 Batch 80: Train Loss = 0.0933\n",
      "Epoch 108 Batch 100: Train Loss = 0.0692\n",
      "Epoch 108 Batch 120: Train Loss = 0.1362\n",
      "Epoch 108: Loss = 0.1009 Valid loss = 0.1271 roc = 0.9445\n",
      "confusion matrix:\n",
      "[[3867   51]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9699021577835083\n",
      "precision class 1 = 0.7866109013557434\n",
      "recall class 0 = 0.9869831800460815\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9444712383073792\n",
      "AUC of PRC = 0.7651439943852995\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6873857069771862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 Batch 0: Train Loss = 0.1046\n",
      "Epoch 109 Batch 20: Train Loss = 0.0900\n",
      "Epoch 109 Batch 40: Train Loss = 0.0769\n",
      "Epoch 109 Batch 60: Train Loss = 0.0772\n",
      "Epoch 109 Batch 80: Train Loss = 0.0793\n",
      "Epoch 109 Batch 100: Train Loss = 0.1291\n",
      "Epoch 109 Batch 120: Train Loss = 0.1404\n",
      "Epoch 109: Loss = 0.1035 Valid loss = 0.1226 roc = 0.9437\n",
      "confusion matrix:\n",
      "[[3860   58]\n",
      " [ 110  198]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.9722921848297119\n",
      "precision class 1 = 0.7734375\n",
      "recall class 0 = 0.9851965308189392\n",
      "recall class 1 = 0.6428571343421936\n",
      "AUC of ROC = 0.9436699084478564\n",
      "AUC of PRC = 0.7666312757966404\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.7021276840447228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 Batch 0: Train Loss = 0.1528\n",
      "Epoch 110 Batch 20: Train Loss = 0.1144\n",
      "Epoch 110 Batch 40: Train Loss = 0.0926\n",
      "Epoch 110 Batch 60: Train Loss = 0.0813\n",
      "Epoch 110 Batch 80: Train Loss = 0.0858\n",
      "Epoch 110 Batch 100: Train Loss = 0.0989\n",
      "Epoch 110 Batch 120: Train Loss = 0.1048\n",
      "Epoch 110: Loss = 0.1043 Valid loss = 0.1258 roc = 0.9430\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9711490273475647\n",
      "precision class 1 = 0.8041666746139526\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9429845932525871\n",
      "AUC of PRC = 0.7655151725682953\n",
      "min(+P, Se) = 0.7175324675324676\n",
      "f1_score = 0.7043795748736088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 Batch 0: Train Loss = 0.1164\n",
      "Epoch 111 Batch 20: Train Loss = 0.0948\n",
      "Epoch 111 Batch 40: Train Loss = 0.0831\n",
      "Epoch 111 Batch 60: Train Loss = 0.0875\n",
      "Epoch 111 Batch 80: Train Loss = 0.0853\n",
      "Epoch 111 Batch 100: Train Loss = 0.0854\n",
      "Epoch 111 Batch 120: Train Loss = 0.0853\n",
      "Epoch 111: Loss = 0.1012 Valid loss = 0.1275 roc = 0.9438\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.969265341758728\n",
      "precision class 1 = 0.8258928656578064\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9437502900366607\n",
      "AUC of PRC = 0.7547536314243878\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6954886999156679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 Batch 0: Train Loss = 0.0754\n",
      "Epoch 112 Batch 20: Train Loss = 0.1297\n",
      "Epoch 112 Batch 40: Train Loss = 0.0859\n",
      "Epoch 112 Batch 60: Train Loss = 0.0909\n",
      "Epoch 112 Batch 80: Train Loss = 0.1378\n",
      "Epoch 112 Batch 100: Train Loss = 0.1414\n",
      "Epoch 112 Batch 120: Train Loss = 0.0900\n",
      "Epoch 112: Loss = 0.1027 Valid loss = 0.1233 roc = 0.9447\n",
      "confusion matrix:\n",
      "[[3865   53]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9706177711486816\n",
      "precision class 1 = 0.7827869057655334\n",
      "recall class 0 = 0.9864726662635803\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9447181838070047\n",
      "AUC of PRC = 0.7587129874887039\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6920290017198099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 Batch 0: Train Loss = 0.0627\n",
      "Epoch 113 Batch 20: Train Loss = 0.1017\n",
      "Epoch 113 Batch 40: Train Loss = 0.1586\n",
      "Epoch 113 Batch 60: Train Loss = 0.0633\n",
      "Epoch 113 Batch 80: Train Loss = 0.1145\n",
      "Epoch 113 Batch 100: Train Loss = 0.0653\n",
      "Epoch 113 Batch 120: Train Loss = 0.1335\n",
      "Epoch 113: Loss = 0.1045 Valid loss = 0.1312 roc = 0.9382\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.967581033706665\n",
      "precision class 1 = 0.8240740895271301\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.938231306722884\n",
      "AUC of PRC = 0.7545165020197213\n",
      "min(+P, Se) = 0.6891025641025641\n",
      "f1_score = 0.67938936636808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 Batch 0: Train Loss = 0.1038\n",
      "Epoch 114 Batch 20: Train Loss = 0.1310\n",
      "Epoch 114 Batch 40: Train Loss = 0.0697\n",
      "Epoch 114 Batch 60: Train Loss = 0.1835\n",
      "Epoch 114 Batch 80: Train Loss = 0.1466\n",
      "Epoch 114 Batch 100: Train Loss = 0.0870\n",
      "Epoch 114 Batch 120: Train Loss = 0.1138\n",
      "Epoch 114: Loss = 0.1031 Valid loss = 0.1251 roc = 0.9449\n",
      "confusion matrix:\n",
      "[[3856   62]\n",
      " [ 111  197]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9720191359519958\n",
      "precision class 1 = 0.760617733001709\n",
      "recall class 0 = 0.9841756224632263\n",
      "recall class 1 = 0.6396104097366333\n",
      "AUC of ROC = 0.9448872337463456\n",
      "AUC of PRC = 0.7628619178573273\n",
      "min(+P, Se) = 0.7142857142857143\n",
      "f1_score = 0.6948853619050325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 Batch 0: Train Loss = 0.0957\n",
      "Epoch 115 Batch 20: Train Loss = 0.1350\n",
      "Epoch 115 Batch 40: Train Loss = 0.0999\n",
      "Epoch 115 Batch 60: Train Loss = 0.1073\n",
      "Epoch 115 Batch 80: Train Loss = 0.1210\n",
      "Epoch 115 Batch 100: Train Loss = 0.0759\n",
      "Epoch 115 Batch 120: Train Loss = 0.1212\n",
      "Epoch 115: Loss = 0.1015 Valid loss = 0.1210 roc = 0.9476\n",
      "confusion matrix:\n",
      "[[3867   51]\n",
      " [ 107  201]]\n",
      "accuracy = 0.9626123905181885\n",
      "precision class 0 = 0.9730749726295471\n",
      "precision class 1 = 0.7976190447807312\n",
      "recall class 0 = 0.9869831800460815\n",
      "recall class 1 = 0.6525974273681641\n",
      "AUC of ROC = 0.947643410698541\n",
      "AUC of PRC = 0.7630097178677434\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.717857127189637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 Batch 0: Train Loss = 0.0931\n",
      "Epoch 116 Batch 20: Train Loss = 0.0941\n",
      "Epoch 116 Batch 40: Train Loss = 0.0750\n",
      "Epoch 116 Batch 60: Train Loss = 0.0712\n",
      "Epoch 116 Batch 80: Train Loss = 0.1232\n",
      "Epoch 116 Batch 100: Train Loss = 0.0537\n",
      "Epoch 116 Batch 120: Train Loss = 0.0803\n",
      "Epoch 116: Loss = 0.1002 Valid loss = 0.1235 roc = 0.9471\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 127  181]]\n",
      "accuracy = 0.9626123905181885\n",
      "precision class 0 = 0.9683607220649719\n",
      "precision class 1 = 0.8537735939025879\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9470906836909899\n",
      "AUC of PRC = 0.7679312244103172\n",
      "min(+P, Se) = 0.6957928802588996\n",
      "f1_score = 0.6961538502309449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 Batch 0: Train Loss = 0.1272\n",
      "Epoch 117 Batch 20: Train Loss = 0.0930\n",
      "Epoch 117 Batch 40: Train Loss = 0.1059\n",
      "Epoch 117 Batch 60: Train Loss = 0.1122\n",
      "Epoch 117 Batch 80: Train Loss = 0.0962\n",
      "Epoch 117 Batch 100: Train Loss = 0.0987\n",
      "Epoch 117 Batch 120: Train Loss = 0.0804\n",
      "Epoch 117: Loss = 0.0983 Valid loss = 0.1231 roc = 0.9493\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 113  195]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9716436862945557\n",
      "precision class 1 = 0.8091286420822144\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.9493455115583753\n",
      "AUC of PRC = 0.7755607025611594\n",
      "min(+P, Se) = 0.7028753993610224\n",
      "f1_score = 0.7103825586117369\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 Batch 0: Train Loss = 0.0846\n",
      "Epoch 118 Batch 20: Train Loss = 0.1080\n",
      "Epoch 118 Batch 40: Train Loss = 0.0618\n",
      "Epoch 118 Batch 60: Train Loss = 0.1103\n",
      "Epoch 118 Batch 80: Train Loss = 0.1212\n",
      "Epoch 118 Batch 100: Train Loss = 0.1005\n",
      "Epoch 118 Batch 120: Train Loss = 0.0846\n",
      "Epoch 118: Loss = 0.0992 Valid loss = 0.1215 roc = 0.9491\n",
      "confusion matrix:\n",
      "[[3870   48]\n",
      " [ 114  194]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9713855385780334\n",
      "precision class 1 = 0.8016529083251953\n",
      "recall class 0 = 0.9877488613128662\n",
      "recall class 1 = 0.6298701167106628\n",
      "AUC of ROC = 0.9490935940017102\n",
      "AUC of PRC = 0.7711444283076807\n",
      "min(+P, Se) = 0.6923076923076923\n",
      "f1_score = 0.7054545139312755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 Batch 0: Train Loss = 0.0737\n",
      "Epoch 119 Batch 20: Train Loss = 0.0947\n",
      "Epoch 119 Batch 40: Train Loss = 0.1293\n",
      "Epoch 119 Batch 60: Train Loss = 0.1021\n",
      "Epoch 119 Batch 80: Train Loss = 0.0937\n",
      "Epoch 119 Batch 100: Train Loss = 0.0999\n",
      "Epoch 119 Batch 120: Train Loss = 0.1164\n",
      "Epoch 119: Loss = 0.1000 Valid loss = 0.1196 roc = 0.9497\n",
      "confusion matrix:\n",
      "[[3862   56]\n",
      " [ 109  199]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9725509881973267\n",
      "precision class 1 = 0.7803921699523926\n",
      "recall class 0 = 0.9857069849967957\n",
      "recall class 1 = 0.6461039185523987\n",
      "AUC of ROC = 0.9497026709890415\n",
      "AUC of PRC = 0.7798503873064411\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.7069272241894827\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 Batch 0: Train Loss = 0.0856\n",
      "Epoch 120 Batch 20: Train Loss = 0.1171\n",
      "Epoch 120 Batch 40: Train Loss = 0.1249\n",
      "Epoch 120 Batch 60: Train Loss = 0.1034\n",
      "Epoch 120 Batch 80: Train Loss = 0.1282\n",
      "Epoch 120 Batch 100: Train Loss = 0.0671\n",
      "Epoch 120 Batch 120: Train Loss = 0.1127\n",
      "Epoch 120: Loss = 0.0988 Valid loss = 0.1203 roc = 0.9479\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9621391296386719\n",
      "precision class 0 = 0.9688123464584351\n",
      "precision class 1 = 0.8394495248794556\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.947854723122717\n",
      "AUC of PRC = 0.7793965575563627\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6958174585829037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 Batch 0: Train Loss = 0.0902\n",
      "Epoch 121 Batch 20: Train Loss = 0.1125\n",
      "Epoch 121 Batch 40: Train Loss = 0.0755\n",
      "Epoch 121 Batch 60: Train Loss = 0.1290\n",
      "Epoch 121 Batch 80: Train Loss = 0.0798\n",
      "Epoch 121 Batch 100: Train Loss = 0.0655\n",
      "Epoch 121 Batch 120: Train Loss = 0.0320\n",
      "Epoch 121: Loss = 0.0964 Valid loss = 0.1263 roc = 0.9494\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9711707234382629\n",
      "precision class 1 = 0.8143460154533386\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9493910887479035\n",
      "AUC of PRC = 0.7761497443282146\n",
      "min(+P, Se) = 0.7119741100323624\n",
      "f1_score = 0.7082568703628083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 Batch 0: Train Loss = 0.0853\n",
      "Epoch 122 Batch 20: Train Loss = 0.1467\n",
      "Epoch 122 Batch 40: Train Loss = 0.0405\n",
      "Epoch 122 Batch 60: Train Loss = 0.0511\n",
      "Epoch 122 Batch 80: Train Loss = 0.1109\n",
      "Epoch 122 Batch 100: Train Loss = 0.0672\n",
      "Epoch 122 Batch 120: Train Loss = 0.1091\n",
      "Epoch 122: Loss = 0.0960 Valid loss = 0.1270 roc = 0.9504\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9690541625022888\n",
      "precision class 1 = 0.8401826620101929\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9504418501355714\n",
      "AUC of PRC = 0.7827874677137022\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6982922078919902\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 Batch 0: Train Loss = 0.0852\n",
      "Epoch 123 Batch 20: Train Loss = 0.0627\n",
      "Epoch 123 Batch 40: Train Loss = 0.0718\n",
      "Epoch 123 Batch 60: Train Loss = 0.0879\n",
      "Epoch 123 Batch 80: Train Loss = 0.1009\n",
      "Epoch 123 Batch 100: Train Loss = 0.0773\n",
      "Epoch 123 Batch 120: Train Loss = 0.0842\n",
      "Epoch 123: Loss = 0.0961 Valid loss = 0.1224 roc = 0.9500\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9704408645629883\n",
      "precision class 1 = 0.811965823173523\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.949994365002022\n",
      "AUC of PRC = 0.7765273728040112\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.7011069745027056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 Batch 0: Train Loss = 0.0691\n",
      "Epoch 124 Batch 20: Train Loss = 0.1295\n",
      "Epoch 124 Batch 40: Train Loss = 0.0993\n",
      "Epoch 124 Batch 60: Train Loss = 0.0757\n",
      "Epoch 124 Batch 80: Train Loss = 0.0785\n",
      "Epoch 124 Batch 100: Train Loss = 0.1039\n",
      "Epoch 124 Batch 120: Train Loss = 0.1113\n",
      "Epoch 124: Loss = 0.1008 Valid loss = 0.1222 roc = 0.9497\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9640321731567383\n",
      "precision class 0 = 0.9707499742507935\n",
      "precision class 1 = 0.8451327681541443\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9497474195023965\n",
      "AUC of PRC = 0.7674567180772779\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.715355822880113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 Batch 0: Train Loss = 0.0955\n",
      "Epoch 125 Batch 20: Train Loss = 0.1244\n",
      "Epoch 125 Batch 40: Train Loss = 0.0658\n",
      "Epoch 125 Batch 60: Train Loss = 0.0768\n",
      "Epoch 125 Batch 80: Train Loss = 0.0828\n",
      "Epoch 125 Batch 100: Train Loss = 0.0809\n",
      "Epoch 125 Batch 120: Train Loss = 0.0485\n",
      "Epoch 125: Loss = 0.0976 Valid loss = 0.1264 roc = 0.9460\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 127  181]]\n",
      "accuracy = 0.9626123905181885\n",
      "precision class 0 = 0.9683607220649719\n",
      "precision class 1 = 0.8537735939025879\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9459512539527852\n",
      "AUC of PRC = 0.7652488637357016\n",
      "min(+P, Se) = 0.6945337620578779\n",
      "f1_score = 0.6961538502309449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 Batch 0: Train Loss = 0.0939\n",
      "Epoch 126 Batch 20: Train Loss = 0.1281\n",
      "Epoch 126 Batch 40: Train Loss = 0.0831\n",
      "Epoch 126 Batch 60: Train Loss = 0.1383\n",
      "Epoch 126 Batch 80: Train Loss = 0.0598\n",
      "Epoch 126 Batch 100: Train Loss = 0.0927\n",
      "Epoch 126 Batch 120: Train Loss = 0.0795\n",
      "Epoch 126: Loss = 0.0985 Valid loss = 0.1263 roc = 0.9454\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9704186320304871\n",
      "precision class 1 = 0.8016877770423889\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9454126144401795\n",
      "AUC of PRC = 0.7605734007526203\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6972477000908117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 Batch 0: Train Loss = 0.1027\n",
      "Epoch 127 Batch 20: Train Loss = 0.0668\n",
      "Epoch 127 Batch 40: Train Loss = 0.1537\n",
      "Epoch 127 Batch 60: Train Loss = 0.1115\n",
      "Epoch 127 Batch 80: Train Loss = 0.1034\n",
      "Epoch 127 Batch 100: Train Loss = 0.1012\n",
      "Epoch 127 Batch 120: Train Loss = 0.1397\n",
      "Epoch 127: Loss = 0.1018 Valid loss = 0.1220 roc = 0.9451\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9628490209579468\n",
      "precision class 0 = 0.9686020612716675\n",
      "precision class 1 = 0.8544601202011108\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9450819726470567\n",
      "AUC of PRC = 0.7660854002186421\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6986563909869834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 Batch 0: Train Loss = 0.0994\n",
      "Epoch 128 Batch 20: Train Loss = 0.0881\n",
      "Epoch 128 Batch 40: Train Loss = 0.1151\n",
      "Epoch 128 Batch 60: Train Loss = 0.1024\n",
      "Epoch 128 Batch 80: Train Loss = 0.1186\n",
      "Epoch 128 Batch 100: Train Loss = 0.1252\n",
      "Epoch 128 Batch 120: Train Loss = 0.1005\n",
      "Epoch 128: Loss = 0.1012 Valid loss = 0.1251 roc = 0.9487\n",
      "confusion matrix:\n",
      "[[3888   30]\n",
      " [ 132  176]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.967164158821106\n",
      "precision class 1 = 0.8543689250946045\n",
      "recall class 0 = 0.992343008518219\n",
      "recall class 1 = 0.5714285969734192\n",
      "AUC of ROC = 0.9487198610475793\n",
      "AUC of PRC = 0.7618068998164489\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6848249474662501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 Batch 0: Train Loss = 0.0991\n",
      "Epoch 129 Batch 20: Train Loss = 0.0503\n",
      "Epoch 129 Batch 40: Train Loss = 0.0905\n",
      "Epoch 129 Batch 60: Train Loss = 0.1571\n",
      "Epoch 129 Batch 80: Train Loss = 0.1071\n",
      "Epoch 129 Batch 100: Train Loss = 0.0964\n",
      "Epoch 129 Batch 120: Train Loss = 0.1214\n",
      "Epoch 129: Loss = 0.1010 Valid loss = 0.1217 roc = 0.9504\n",
      "confusion matrix:\n",
      "[[3855   63]\n",
      " [ 109  199]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9725025296211243\n",
      "precision class 1 = 0.7595419883728027\n",
      "recall class 0 = 0.9839203953742981\n",
      "recall class 1 = 0.6461039185523987\n",
      "AUC of ROC = 0.9503796994225784\n",
      "AUC of PRC = 0.7687858896274958\n",
      "min(+P, Se) = 0.6945337620578779\n",
      "f1_score = 0.6982456582903911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 Batch 0: Train Loss = 0.0863\n",
      "Epoch 130 Batch 20: Train Loss = 0.0721\n",
      "Epoch 130 Batch 40: Train Loss = 0.1501\n",
      "Epoch 130 Batch 60: Train Loss = 0.0798\n",
      "Epoch 130 Batch 80: Train Loss = 0.0928\n",
      "Epoch 130 Batch 100: Train Loss = 0.1034\n",
      "Epoch 130 Batch 120: Train Loss = 0.1175\n",
      "Epoch 130: Loss = 0.0998 Valid loss = 0.1299 roc = 0.9503\n",
      "confusion matrix:\n",
      "[[3893   25]\n",
      " [ 131  177]]\n",
      "accuracy = 0.9630856513977051\n",
      "precision class 0 = 0.9674453139305115\n",
      "precision class 1 = 0.8762376308441162\n",
      "recall class 0 = 0.9936192035675049\n",
      "recall class 1 = 0.5746753215789795\n",
      "AUC of ROC = 0.9503465523756489\n",
      "AUC of PRC = 0.7695445289077207\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.6941176470221578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 Batch 0: Train Loss = 0.1133\n",
      "Epoch 131 Batch 20: Train Loss = 0.0716\n",
      "Epoch 131 Batch 40: Train Loss = 0.1011\n",
      "Epoch 131 Batch 60: Train Loss = 0.1681\n",
      "Epoch 131 Batch 80: Train Loss = 0.1071\n",
      "Epoch 131 Batch 100: Train Loss = 0.0762\n",
      "Epoch 131 Batch 120: Train Loss = 0.0912\n",
      "Epoch 131: Loss = 0.0993 Valid loss = 0.1221 roc = 0.9465\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 113  195]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9715866446495056\n",
      "precision class 1 = 0.7831325531005859\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.946544586092825\n",
      "AUC of PRC = 0.765301854258036\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.7001795238182712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 Batch 0: Train Loss = 0.0959\n",
      "Epoch 132 Batch 20: Train Loss = 0.0699\n",
      "Epoch 132 Batch 40: Train Loss = 0.0992\n",
      "Epoch 132 Batch 60: Train Loss = 0.0790\n",
      "Epoch 132 Batch 80: Train Loss = 0.1357\n",
      "Epoch 132 Batch 100: Train Loss = 0.0545\n",
      "Epoch 132 Batch 120: Train Loss = 0.0768\n",
      "Epoch 132: Loss = 0.0980 Valid loss = 0.1244 roc = 0.9515\n",
      "confusion matrix:\n",
      "[[3856   62]\n",
      " [ 104  204]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.973737359046936\n",
      "precision class 1 = 0.7669172883033752\n",
      "recall class 0 = 0.9841756224632263\n",
      "recall class 1 = 0.6623376607894897\n",
      "AUC of ROC = 0.9515481328268465\n",
      "AUC of PRC = 0.7761937803878605\n",
      "min(+P, Se) = 0.724025974025974\n",
      "f1_score = 0.7108013610766104\n",
      "------------ Save best model - AUROC: 0.9515 ------------\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 Batch 0: Train Loss = 0.0690\n",
      "Epoch 133 Batch 20: Train Loss = 0.1203\n",
      "Epoch 133 Batch 40: Train Loss = 0.1162\n",
      "Epoch 133 Batch 60: Train Loss = 0.0971\n",
      "Epoch 133 Batch 80: Train Loss = 0.1189\n",
      "Epoch 133 Batch 100: Train Loss = 0.0746\n",
      "Epoch 133 Batch 120: Train Loss = 0.0965\n",
      "Epoch 133: Loss = 0.0980 Valid loss = 0.1289 roc = 0.9440\n",
      "confusion matrix:\n",
      "[[3881   37]\n",
      " [ 127  181]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9683133959770203\n",
      "precision class 1 = 0.8302752375602722\n",
      "recall class 0 = 0.9905564188957214\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9439723752510889\n",
      "AUC of PRC = 0.7637922116616986\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6882129605659664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 Batch 0: Train Loss = 0.0679\n",
      "Epoch 134 Batch 20: Train Loss = 0.1061\n",
      "Epoch 134 Batch 40: Train Loss = 0.0982\n",
      "Epoch 134 Batch 60: Train Loss = 0.0482\n",
      "Epoch 134 Batch 80: Train Loss = 0.0926\n",
      "Epoch 134 Batch 100: Train Loss = 0.1072\n",
      "Epoch 134 Batch 120: Train Loss = 0.0757\n",
      "Epoch 134: Loss = 0.1019 Valid loss = 0.1224 roc = 0.9454\n",
      "confusion matrix:\n",
      "[[3863   55]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.970846951007843\n",
      "precision class 1 = 0.7773279547691345\n",
      "recall class 0 = 0.9859622120857239\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9453546071080527\n",
      "AUC of PRC = 0.7621900467371721\n",
      "min(+P, Se) = 0.6893203883495146\n",
      "f1_score = 0.6918918606565628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 Batch 0: Train Loss = 0.0719\n",
      "Epoch 135 Batch 20: Train Loss = 0.0574\n",
      "Epoch 135 Batch 40: Train Loss = 0.0737\n",
      "Epoch 135 Batch 60: Train Loss = 0.1076\n",
      "Epoch 135 Batch 80: Train Loss = 0.1061\n",
      "Epoch 135 Batch 100: Train Loss = 0.1009\n",
      "Epoch 135 Batch 120: Train Loss = 0.1111\n",
      "Epoch 135: Loss = 0.0984 Valid loss = 0.1220 roc = 0.9482\n",
      "confusion matrix:\n",
      "[[3853   65]\n",
      " [ 105  203]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.973471462726593\n",
      "precision class 1 = 0.7574626803398132\n",
      "recall class 0 = 0.9834098815917969\n",
      "recall class 1 = 0.6590909361839294\n",
      "AUC of ROC = 0.9481737634494144\n",
      "AUC of PRC = 0.7646139419663116\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.7048611239081727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 Batch 0: Train Loss = 0.0909\n",
      "Epoch 136 Batch 20: Train Loss = 0.0981\n",
      "Epoch 136 Batch 40: Train Loss = 0.0853\n",
      "Epoch 136 Batch 60: Train Loss = 0.0835\n",
      "Epoch 136 Batch 80: Train Loss = 0.0554\n",
      "Epoch 136 Batch 100: Train Loss = 0.0792\n",
      "Epoch 136 Batch 120: Train Loss = 0.0732\n",
      "Epoch 136: Loss = 0.0959 Valid loss = 0.1223 roc = 0.9495\n",
      "confusion matrix:\n",
      "[[3858   60]\n",
      " [ 113  195]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9715436697006226\n",
      "precision class 1 = 0.7647058963775635\n",
      "recall class 0 = 0.9846860766410828\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.9495104181168501\n",
      "AUC of PRC = 0.7705839171149049\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6927175712423592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 Batch 0: Train Loss = 0.0875\n",
      "Epoch 137 Batch 20: Train Loss = 0.1329\n",
      "Epoch 137 Batch 40: Train Loss = 0.1025\n",
      "Epoch 137 Batch 60: Train Loss = 0.1053\n",
      "Epoch 137 Batch 80: Train Loss = 0.0736\n",
      "Epoch 137 Batch 100: Train Loss = 0.1542\n",
      "Epoch 137 Batch 120: Train Loss = 0.1016\n",
      "Epoch 137: Loss = 0.0979 Valid loss = 0.1193 roc = 0.9490\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.969273030757904\n",
      "precision class 1 = 0.8295964002609253\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9489999535941344\n",
      "AUC of PRC = 0.777622144856766\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6967984932387027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 Batch 0: Train Loss = 0.1000\n",
      "Epoch 138 Batch 20: Train Loss = 0.0555\n",
      "Epoch 138 Batch 40: Train Loss = 0.1141\n",
      "Epoch 138 Batch 60: Train Loss = 0.1610\n",
      "Epoch 138 Batch 80: Train Loss = 0.0771\n",
      "Epoch 138 Batch 100: Train Loss = 0.1010\n",
      "Epoch 138 Batch 120: Train Loss = 0.1429\n",
      "Epoch 138: Loss = 0.0976 Valid loss = 0.1207 roc = 0.9497\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9694465398788452\n",
      "precision class 1 = 0.7982832789421082\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9497242165695459\n",
      "AUC of PRC = 0.7594946108829723\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.6876155186085415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 Batch 0: Train Loss = 0.0982\n",
      "Epoch 139 Batch 20: Train Loss = 0.0641\n",
      "Epoch 139 Batch 40: Train Loss = 0.0692\n",
      "Epoch 139 Batch 60: Train Loss = 0.0916\n",
      "Epoch 139 Batch 80: Train Loss = 0.0768\n",
      "Epoch 139 Batch 100: Train Loss = 0.1169\n",
      "Epoch 139 Batch 120: Train Loss = 0.0911\n",
      "Epoch 139: Loss = 0.0952 Valid loss = 0.1320 roc = 0.9470\n",
      "confusion matrix:\n",
      "[[3861   57]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9576431512832642\n",
      "precision class 0 = 0.9693698287010193\n",
      "precision class 1 = 0.7654321193695068\n",
      "recall class 0 = 0.9854517579078674\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9470417917967687\n",
      "AUC of PRC = 0.7527415227707803\n",
      "min(+P, Se) = 0.6785714285714286\n",
      "f1_score = 0.6751360807510209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 Batch 0: Train Loss = 0.1093\n",
      "Epoch 140 Batch 20: Train Loss = 0.0850\n",
      "Epoch 140 Batch 40: Train Loss = 0.1188\n",
      "Epoch 140 Batch 60: Train Loss = 0.1252\n",
      "Epoch 140 Batch 80: Train Loss = 0.0962\n",
      "Epoch 140 Batch 100: Train Loss = 0.0776\n",
      "Epoch 140 Batch 120: Train Loss = 0.0529\n",
      "Epoch 140: Loss = 0.0943 Valid loss = 0.1325 roc = 0.9480\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 127  181]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9682658910751343\n",
      "precision class 1 = 0.8080357313156128\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9480088568909396\n",
      "AUC of PRC = 0.7581518071384638\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.680451134895684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 Batch 0: Train Loss = 0.0999\n",
      "Epoch 141 Batch 20: Train Loss = 0.1147\n",
      "Epoch 141 Batch 40: Train Loss = 0.0886\n",
      "Epoch 141 Batch 60: Train Loss = 0.1062\n",
      "Epoch 141 Batch 80: Train Loss = 0.1199\n",
      "Epoch 141 Batch 100: Train Loss = 0.0862\n",
      "Epoch 141 Batch 120: Train Loss = 0.1119\n",
      "Epoch 141: Loss = 0.0986 Valid loss = 0.1292 roc = 0.9465\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 114  194]]\n",
      "accuracy = 0.9621391296386719\n",
      "precision class 0 = 0.9713999032974243\n",
      "precision class 1 = 0.8083333373069763\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6298701167106628\n",
      "AUC of ROC = 0.9464840927321785\n",
      "AUC of PRC = 0.7562137855407165\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.708029190290653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 Batch 0: Train Loss = 0.1619\n",
      "Epoch 142 Batch 20: Train Loss = 0.0695\n",
      "Epoch 142 Batch 40: Train Loss = 0.0920\n",
      "Epoch 142 Batch 60: Train Loss = 0.1296\n",
      "Epoch 142 Batch 80: Train Loss = 0.1175\n",
      "Epoch 142 Batch 100: Train Loss = 0.0885\n",
      "Epoch 142 Batch 120: Train Loss = 0.1163\n",
      "Epoch 142: Loss = 0.0973 Valid loss = 0.1235 roc = 0.9473\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 119  189]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9701904058456421\n",
      "precision class 1 = 0.807692289352417\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.6136363744735718\n",
      "AUC of ROC = 0.9472804505346618\n",
      "AUC of PRC = 0.7598448344825758\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6974169743320612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 Batch 0: Train Loss = 0.1242\n",
      "Epoch 143 Batch 20: Train Loss = 0.1246\n",
      "Epoch 143 Batch 40: Train Loss = 0.0915\n",
      "Epoch 143 Batch 60: Train Loss = 0.0828\n",
      "Epoch 143 Batch 80: Train Loss = 0.0826\n",
      "Epoch 143 Batch 100: Train Loss = 0.1224\n",
      "Epoch 143 Batch 120: Train Loss = 0.0645\n",
      "Epoch 143: Loss = 0.0966 Valid loss = 0.1396 roc = 0.9452\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.968023955821991\n",
      "precision class 1 = 0.8071748614311218\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9452187042156415\n",
      "AUC of PRC = 0.765506127484768\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.677966101606554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Batch 0: Train Loss = 0.0855\n",
      "Epoch 144 Batch 20: Train Loss = 0.0946\n",
      "Epoch 144 Batch 40: Train Loss = 0.1290\n",
      "Epoch 144 Batch 60: Train Loss = 0.0809\n",
      "Epoch 144 Batch 80: Train Loss = 0.0705\n",
      "Epoch 144 Batch 100: Train Loss = 0.0507\n",
      "Epoch 144 Batch 120: Train Loss = 0.0658\n",
      "Epoch 144: Loss = 0.0965 Valid loss = 0.1292 roc = 0.9455\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9689689874649048\n",
      "precision class 1 = 0.800000011920929\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.945490510000464\n",
      "AUC of PRC = 0.7607846072167309\n",
      "min(+P, Se) = 0.686084142394822\n",
      "f1_score = 0.6840148871847869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 Batch 0: Train Loss = 0.0913\n",
      "Epoch 145 Batch 20: Train Loss = 0.1423\n",
      "Epoch 145 Batch 40: Train Loss = 0.1126\n",
      "Epoch 145 Batch 60: Train Loss = 0.0922\n",
      "Epoch 145 Batch 80: Train Loss = 0.0551\n",
      "Epoch 145 Batch 100: Train Loss = 0.0914\n",
      "Epoch 145 Batch 120: Train Loss = 0.0837\n",
      "Epoch 145: Loss = 0.1004 Valid loss = 0.1245 roc = 0.9503\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 127  181]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.96829754114151\n",
      "precision class 1 = 0.8227272629737854\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9502545693204192\n",
      "AUC of PRC = 0.7700735635987859\n",
      "min(+P, Se) = 0.6990291262135923\n",
      "f1_score = 0.6856060292985715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 Batch 0: Train Loss = 0.1022\n",
      "Epoch 146 Batch 20: Train Loss = 0.1106\n",
      "Epoch 146 Batch 40: Train Loss = 0.1132\n",
      "Epoch 146 Batch 60: Train Loss = 0.0534\n",
      "Epoch 146 Batch 80: Train Loss = 0.1024\n",
      "Epoch 146 Batch 100: Train Loss = 0.0720\n",
      "Epoch 146 Batch 120: Train Loss = 0.0468\n",
      "Epoch 146: Loss = 0.0982 Valid loss = 0.1311 roc = 0.9443\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9697045683860779\n",
      "precision class 1 = 0.806034505367279\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.944349422909913\n",
      "AUC of PRC = 0.7526519243122539\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6925926064790848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 Batch 0: Train Loss = 0.1136\n",
      "Epoch 147 Batch 20: Train Loss = 0.0653\n",
      "Epoch 147 Batch 40: Train Loss = 0.0829\n",
      "Epoch 147 Batch 60: Train Loss = 0.1657\n",
      "Epoch 147 Batch 80: Train Loss = 0.0514\n",
      "Epoch 147 Batch 100: Train Loss = 0.0889\n",
      "Epoch 147 Batch 120: Train Loss = 0.0931\n",
      "Epoch 147: Loss = 0.0973 Valid loss = 0.1253 roc = 0.9410\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9697045683860779\n",
      "precision class 1 = 0.806034505367279\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.940971738827788\n",
      "AUC of PRC = 0.7607390060379206\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6925926064790848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Batch 0: Train Loss = 0.1026\n",
      "Epoch 148 Batch 20: Train Loss = 0.0594\n",
      "Epoch 148 Batch 40: Train Loss = 0.1065\n",
      "Epoch 148 Batch 60: Train Loss = 0.0700\n",
      "Epoch 148 Batch 80: Train Loss = 0.0717\n",
      "Epoch 148 Batch 100: Train Loss = 0.0779\n",
      "Epoch 148 Batch 120: Train Loss = 0.1139\n",
      "Epoch 148: Loss = 0.0954 Valid loss = 0.1270 roc = 0.9497\n",
      "confusion matrix:\n",
      "[[3858   60]\n",
      " [ 111  197]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9720332622528076\n",
      "precision class 1 = 0.7665369510650635\n",
      "recall class 0 = 0.9846860766410828\n",
      "recall class 1 = 0.6396104097366333\n",
      "AUC of ROC = 0.9496993562843488\n",
      "AUC of PRC = 0.7679970264954991\n",
      "min(+P, Se) = 0.7087378640776699\n",
      "f1_score = 0.6973451389468387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 Batch 0: Train Loss = 0.0979\n",
      "Epoch 149 Batch 20: Train Loss = 0.0820\n",
      "Epoch 149 Batch 40: Train Loss = 0.0685\n",
      "Epoch 149 Batch 60: Train Loss = 0.0824\n",
      "Epoch 149 Batch 80: Train Loss = 0.0712\n",
      "Epoch 149 Batch 100: Train Loss = 0.0434\n",
      "Epoch 149 Batch 120: Train Loss = 0.1286\n",
      "Epoch 149: Loss = 0.0956 Valid loss = 0.1247 roc = 0.9502\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9676375389099121\n",
      "precision class 1 = 0.8516746163368225\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.9501849605218671\n",
      "AUC of PRC = 0.7720148495879767\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.688588048117687\n",
      "auroc 0.9515\n",
      "auprc 0.7828\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_minpse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2b9a8924119c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auroc %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_auroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auprc %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_auprc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'minpse %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_minpse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_minpse' is not defined"
     ]
    }
   ],
   "source": [
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "global_best = 0\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "history = []\n",
    "\n",
    "pad_token = np.zeros(33)\n",
    "# begin_time = time.time()\n",
    "best_auroc = 0\n",
    "best_auprc = 0\n",
    "best_sum = 0\n",
    "\n",
    "    \n",
    "file_name = './model/concare-mean-challenge-gru-newnormboost0.1'\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    counter_batch = 0\n",
    "    model.train()  \n",
    "\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(train_x, train_y, train_mask_x, train_x_len, batch_size, shuffle=True)):  \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "#        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt, decov_loss, _ = model(batch_x, batch_lens)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "\n",
    "        model_loss =  BCE_Loss + 1000 * decov_loss\n",
    "\n",
    "        loss = model_loss\n",
    "\n",
    "        epoch_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    total_train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = []\n",
    "        valid_true = []\n",
    "        valid_pred = []\n",
    "        for batch_x, batch_y, batch_mask_x, batch_lens in batch_iter(dev_x, dev_y, dev_mask_x, dev_x_len, batch_size):\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "            batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "#            masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "\n",
    "            opt, decov_loss, _ = model(batch_x, batch_lens)\n",
    "\n",
    "            BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#                 REC_Loss = F.mse_loss(recon, batch_x, reduction='mean').to(device)\n",
    "\n",
    "            valid_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "\n",
    "            y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "            y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "        valid_loss = np.mean(valid_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "        y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "        ret = metrics.print_metrics_binary(y_true, y_pred,verbose = 0)\n",
    "        history.append(ret)\n",
    "        #print()\n",
    "\n",
    "        print('Epoch %d: Loss = %.4f Valid loss = %.4f roc = %.4f'%(each_epoch, total_train_loss[-1], total_valid_loss[-1], ret['auroc']))\n",
    "        metrics.print_metrics_binary(y_true, y_pred)\n",
    "\n",
    "        cur_auroc = ret['auroc']\n",
    "        if cur_auroc > best_auroc:\n",
    "            best_auroc = cur_auroc\n",
    "#             best_auprc = ret['auprc']\n",
    "#             best_minpse = ret['minpse']\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name)\n",
    "            print('------------ Save best model - AUROC: %.4f ------------'%cur_auroc) \n",
    "        \n",
    "        cur_prc = ret['auprc']\n",
    "        cur_minpse = ret['minpse']\n",
    "        \n",
    "        if cur_prc > best_auprc:\n",
    "            best_auprc = cur_prc\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name+\"prc\")\n",
    "            print('\\n------------ Save best-prc model ------------\\n')\n",
    "\n",
    "        cur_sum = cur_auroc + cur_prc + cur_minpse\n",
    "    #     print(cur_sum)\n",
    "        if cur_sum > best_sum:\n",
    "            best_sum = cur_sum\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name+\"sum\")\n",
    "            print('\\n------------ Save best-sum model ------------\\n')\n",
    "\n",
    "print('auroc %.4f'%(best_auroc))\n",
    "print('auprc %.4f'%(best_auprc))\n",
    "print('minpse %.4f'%(best_minpse))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T02:27:47.665388Z",
     "start_time": "2021-10-05T02:27:47.660200Z"
    }
   },
   "outputs": [],
   "source": [
    "# ####Plot Loss\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(1, 1, 1)\n",
    "# x_axis = np.arange(1, 151)\n",
    "# ax1.plot(x_axis, total_train_loss, c='red', label='train')\n",
    "# ax1.plot(x_axis, total_valid_loss, c='blue', label='valid')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T02:27:47.935449Z",
     "start_time": "2021-10-05T02:27:47.824913Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last saved model is in epoch 132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vanilla_transformer_encoder(\n",
       "  (PositionalEncoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0)\n",
       "  )\n",
       "  (GRUs): ModuleList(\n",
       "    (0): GRU(1, 32, batch_first=True)\n",
       "    (1): GRU(1, 32, batch_first=True)\n",
       "    (2): GRU(1, 32, batch_first=True)\n",
       "    (3): GRU(1, 32, batch_first=True)\n",
       "    (4): GRU(1, 32, batch_first=True)\n",
       "    (5): GRU(1, 32, batch_first=True)\n",
       "    (6): GRU(1, 32, batch_first=True)\n",
       "    (7): GRU(1, 32, batch_first=True)\n",
       "    (8): GRU(1, 32, batch_first=True)\n",
       "    (9): GRU(1, 32, batch_first=True)\n",
       "    (10): GRU(1, 32, batch_first=True)\n",
       "    (11): GRU(1, 32, batch_first=True)\n",
       "    (12): GRU(1, 32, batch_first=True)\n",
       "    (13): GRU(1, 32, batch_first=True)\n",
       "    (14): GRU(1, 32, batch_first=True)\n",
       "    (15): GRU(1, 32, batch_first=True)\n",
       "    (16): GRU(1, 32, batch_first=True)\n",
       "    (17): GRU(1, 32, batch_first=True)\n",
       "    (18): GRU(1, 32, batch_first=True)\n",
       "    (19): GRU(1, 32, batch_first=True)\n",
       "    (20): GRU(1, 32, batch_first=True)\n",
       "    (21): GRU(1, 32, batch_first=True)\n",
       "    (22): GRU(1, 32, batch_first=True)\n",
       "    (23): GRU(1, 32, batch_first=True)\n",
       "    (24): GRU(1, 32, batch_first=True)\n",
       "    (25): GRU(1, 32, batch_first=True)\n",
       "    (26): GRU(1, 32, batch_first=True)\n",
       "    (27): GRU(1, 32, batch_first=True)\n",
       "    (28): GRU(1, 32, batch_first=True)\n",
       "    (29): GRU(1, 32, batch_first=True)\n",
       "    (30): GRU(1, 32, batch_first=True)\n",
       "    (31): GRU(1, 32, batch_first=True)\n",
       "    (32): GRU(1, 32, batch_first=True)\n",
       "  )\n",
       "  (FinalAttentionQKV): FinalAttentionQKV(\n",
       "    (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_out): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (tanh): Tanh()\n",
       "    (softmax): Softmax()\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (MultiHeadedAttention): MultiHeadedAttention(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (final_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (softmax): Softmax()\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (SublayerConnection): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (PositionwiseFeedForward): PositionwiseFeedForward(\n",
       "    (w_1): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (w_2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (demo_proj_main): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (demo_proj): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (tanh): Tanh()\n",
       "  (softmax): Softmax()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(file_name+'sum')\n",
    "save_epoch = checkpoint['epoch']\n",
    "print(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T02:27:58.803018Z",
     "start_time": "2021-10-05T02:27:48.052497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Test Loss = 0.0990\n",
      "\n",
      "==>Predicting on test\n",
      "Test Loss = 0.1233\n",
      "confusion matrix:\n",
      "[[3669   72]\n",
      " [  94  200]]\n",
      "accuracy = 0.9588599801063538\n",
      "precision class 0 = 0.9750199317932129\n",
      "precision class 1 = 0.7352941036224365\n",
      "recall class 0 = 0.9807537794113159\n",
      "recall class 1 = 0.680272102355957\n",
      "AUC of ROC = 0.9557750392324799\n",
      "AUC of PRC = 0.7902974773219105\n",
      "min(+P, Se) = 0.6938775510204082\n",
      "f1_score = 0.7067137709400907\n"
     ]
    }
   ],
   "source": [
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(test_x, test_y, test_mask_x, test_x_len, batch_size, shuffle=True)):  \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt, decov_loss, _ = model(batch_x, batch_lens)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "\n",
    "        model_loss =  BCE_Loss \n",
    "\n",
    "        loss = model_loss\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        if step % 20 == 0:\n",
    "            print('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "        y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "print(\"\\n==>Predicting on test\")\n",
    "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "test_res = metrics.print_metrics_binary(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T02:36:06.203588Z",
     "start_time": "2021-10-05T02:35:49.407214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc 0.9559(0.0061, 0.9435-0.9669)\n",
      "auprc 0.7905(0.0216, 0.7463-0.8314)\n",
      "minpse 0.6976(0.0240, 0.6496-0.7416)\n",
      "f1 0.7063(0.0227, 0.6626-0.7481)\n",
      "acc 0.9589(0.0031, 0.9524-0.9651)\n",
      "pre0 0.9750(0.0026, 0.9700-0.9800)\n",
      "pre1 0.7366(0.0278, 0.6831-0.7909)\n",
      "rec0 0.9809(0.0023, 0.9764-0.9853)\n",
      "rec1 0.6791(0.0283, 0.6219-0.7338)\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap\n",
    "N = len(y_true)\n",
    "N_idx = np.arange(N)\n",
    "K = 1000\n",
    "\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "\n",
    "\n",
    "acc = []# TN+TP/ALL\n",
    "pre0 = []\n",
    "pre1 = [] # TP/TP+FP = PPV = precision\n",
    "rec0 = [] # TN/TN+FP = TNR = specificity = selectivity\n",
    "rec1 = []# TP/TP+FN = recall = TPR = sensitivity\n",
    "f1 = []\n",
    "\n",
    "\n",
    "for i in range(K):\n",
    "    boot_idx = np.random.choice(N_idx, N, replace=True)\n",
    "    boot_true = np.array(y_true)[boot_idx]\n",
    "    boot_pred = y_pred[boot_idx, :]\n",
    "    test_ret = metrics.print_metrics_binary(boot_true, boot_pred, verbose=0)\n",
    "    auroc.append(test_ret['auroc'])\n",
    "    auprc.append(test_ret['auprc'])\n",
    "    minpse.append(test_ret['minpse'])\n",
    "    acc.append(test_ret['acc'])\n",
    "    pre0.append(test_ret['prec0'])\n",
    "    pre1.append(test_ret['prec1'])\n",
    "    rec0.append(test_ret['rec0'])\n",
    "    rec1.append(test_ret['rec1'])\n",
    "    f1.append(test_ret['f1_score'])\n",
    "#     print('%d/%d'%(i+1,K))\n",
    "    \n",
    "auroc = np.sort(auroc)\n",
    "auprc = np.sort(auprc)\n",
    "minpse = np.sort(minpse)\n",
    "\n",
    "acc = np.sort(acc)\n",
    "pre0 = np.sort(pre0)\n",
    "pre1 = np.sort(pre1)\n",
    "rec0 = np.sort(rec0)\n",
    "rec1 = np.sort(rec1)\n",
    "f1 = np.sort(f1)\n",
    "\n",
    "print('auroc %.4f(%.4f, %.4f-%.4f)'%(np.mean(auroc), np.std(auroc), auroc[int(K*0.025)], auroc[int(K*0.975)]))\n",
    "print('auprc %.4f(%.4f, %.4f-%.4f)'%(np.mean(auprc), np.std(auprc), auprc[int(K*0.025)], auprc[int(K*0.975)]))\n",
    "print('minpse %.4f(%.4f, %.4f-%.4f)'%(np.mean(minpse), np.std(minpse), minpse[int(K*0.025)], minpse[int(K*0.975)]))\n",
    "print('f1 %.4f(%.4f, %.4f-%.4f)'%(np.mean(f1), np.std(f1), f1[int(K*0.025)], f1[int(K*0.975)]))\n",
    "print('acc %.4f(%.4f, %.4f-%.4f)'%(np.mean(acc), np.std(acc), acc[int(K*0.025)], acc[int(K*0.975)]))\n",
    "print('pre0 %.4f(%.4f, %.4f-%.4f)'%(np.mean(pre0), np.std(pre0), pre0[int(K*0.025)], pre0[int(K*0.975)]))\n",
    "print('pre1 %.4f(%.4f, %.4f-%.4f)'%(np.mean(pre1), np.std(pre1), pre1[int(K*0.025)], pre1[int(K*0.975)]))\n",
    "\n",
    "print('rec0 %.4f(%.4f, %.4f-%.4f)'%(np.mean(rec0), np.std(rec0), rec0[int(K*0.025)], rec0[int(K*0.975)]))\n",
    "print('rec1 %.4f(%.4f, %.4f-%.4f)'%(np.mean(rec1), np.std(rec1), rec1[int(K*0.025)], rec1[int(K*0.975)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base1)",
   "language": "python",
   "name": "base1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
